"""
BlindInsight AIì˜ ê¸°ë³¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ë° ìœ í‹¸ë¦¬í‹°

ğŸ—ï¸ í•µì‹¬ êµ¬ì¡°:
- BaseAgent: ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
- RAG ì‹œìŠ¤í…œ: ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
- MCP í†µí•©: ì™¸ë¶€ ë°ì´í„° ì œê³µìì™€ í†µì‹ 
- LLM ìƒì„±: OpenAI GPT ëª¨ë¸ì„ í†µí•œ ì‘ë‹µ ìƒì„±
- ì„±ëŠ¥ ì¶”ì : ì‹¤í–‰ ì‹œê°„ ë° ì„±ê³µë¥  ëª¨ë‹ˆí„°ë§
"""

import asyncio
import time
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Type, Union

from langchain.schema import Document
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage

from ..models.base import BaseModel, settings
from ..models.user import UserProfile
from ..rag.knowledge_base import KnowledgeBase
from ..rag.retriever import RAGRetriever


class AgentResult(BaseModel):
    """
    ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹´ëŠ” ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤
    
    ğŸ¯ ì£¼ìš” ì •ë³´:
    - ì‹¤í–‰ ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€
    - ë¶„ì„ ê²°ê³¼ ë°ì´í„°
    - ì‹¤í–‰ ì‹œê°„ ë° ì‹ ë¢°ë„ ì ìˆ˜
    - ë©”íƒ€ë°ì´í„° ë° ì˜¤ë¥˜ ì •ë³´
    
    ğŸ“Š ì‚¬ìš© ìš©ë„:
    - ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰ ê²°ê³¼ í‘œì¤€í™”
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…
    - ê²°ê³¼ ì§‘ê³„ ë° ë¶„ì„
    """
    
    agent_name: str  # ì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "culture_analysis", "compensation_analysis")
    success: bool  # ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€ (True: ì„±ê³µ, False: ì‹¤íŒ¨)
    result: Optional[Dict[str, Any]] = None  # ë¶„ì„ ê²°ê³¼ ë°ì´í„° (JSON í˜•íƒœ)
    error_message: Optional[str] = None  # ì—ëŸ¬ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€
    execution_time: float = 0.0  # ì‹¤í–‰ ì†Œìš” ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
    confidence_score: float = 0.0  # ê²°ê³¼ ì‹ ë¢°ë„ ì ìˆ˜ (0.0~1.0)
    metadata: Dict[str, Any] = {}  # ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì»¨í…ìŠ¤íŠ¸, ì„¤ì •ê°’ ë“±)
    
    class Config:
        """Pydantic ì„¤ì • í´ë˜ìŠ¤ - ìŠ¤í‚¤ë§ˆ ì˜ˆì œ ì •ì˜"""
        schema_extra = {
            "example": {
                "agent_name": "culture_analysis",  # íšŒì‚¬ ë¬¸í™” ë¶„ì„ ì—ì´ì „íŠ¸
                "success": True,  # ì„±ê³µì  ì‹¤í–‰
                "result": {"culture_score": 85},  # ë¬¸í™” ì ìˆ˜ 85ì 
                "execution_time": 12.5,  # 12.5ì´ˆ ì†Œìš”
                "confidence_score": 0.88  # ì‹ ë¢°ë„ 88%
            }
        }


class AgentConfig(BaseModel):
    """
    ì—ì´ì „íŠ¸ ë™ì‘ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” êµ¬ì„± í´ë˜ìŠ¤
    
    ğŸ”§ ì„¤ì • ë¶„ì•¼:
    - LLM ì„¤ì •: ëª¨ë¸ëª…, ì˜¨ë„, í† í° ìˆ˜
    - RAG ì„¤ì •: ê²€ìƒ‰ ê°œìˆ˜, ìœ ì‚¬ë„ ì„ê³„ê°’
    - ì„±ëŠ¥ ì„¤ì •: ìºì‹±, ì¬ì‹œë„, TTL
    - í’ˆì§ˆ ì„¤ì •: ê²€ì¦, ì‹ ë¢°ë„ ì„ê³„ê°’
    
    ğŸ’¡ ì‚¬ìš©ë²•:
    - ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê±°ë‚˜ í•„ìš”í•œ ê°’ë§Œ ì˜¤ë²„ë¼ì´ë“œ
    - ì—ì´ì „íŠ¸ë³„ë¡œ ë‹¤ë¥¸ ì„¤ì •ì„ ì ìš© ê°€ëŠ¥
    - ìš´ì˜ í™˜ê²½ì— ë”°ë¼ ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥
    """ 
    
    # LLM ì„¤ì • - OpenAI ëª¨ë¸ ê´€ë ¨
    model_name: str = "gpt-4o-mini-2024-07-18"  # ì‚¬ìš©í•  GPT ëª¨ë¸ëª…
    temperature: float = 0.4  # ì‘ë‹µ ì°½ì˜ì„± (0.0: ì¼ê´€ì„±, 1.0: ì°½ì˜ì„±)
    max_tokens: int = 4000  # ìµœëŒ€ ìƒì„± í† í° ìˆ˜
    timeout: int = 60  # API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    
    # RAG ê²€ìƒ‰ ì„¤ì • - ChromaDB ë²¡í„° ê²€ìƒ‰
    max_retrievals: int = 50  # ê²€ìƒ‰í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
    relevance_threshold: float = 0.3  # ê´€ë ¨ì„± ì ìˆ˜ ì„ê³„ê°’ (0.0~1.0)  
    enable_reranking: bool = True  # ì¬ìˆœìœ„ ë§¤ê¹€ í™œì„±í™”
    keyword_match_threshold: float = 0.005  # í‚¤ì›Œë“œ ë§¤ì¹­ ì„ê³„ê°’ (0.0~1.0)
    
    # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    enable_caching: bool = True  # ê²°ê³¼ ìºì‹± í™œì„±í™”
    cache_ttl: int = 3600  # ìºì‹œ ìœ ì§€ ì‹œê°„ (ì´ˆ, 1ì‹œê°„)
    max_retries: int = 3  # ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    # í’ˆì§ˆ ê´€ë¦¬ ì„¤ì •
    min_confidence_threshold: float = 0.6  # ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’
    require_sources: bool = True  # ì¶œì²˜ ì •ë³´ í•„ìˆ˜ ì—¬ë¶€
    validate_outputs: bool = False  # ì¶œë ¥ ê²°ê³¼ ê²€ì¦ í™œì„±í™”
    
    class Config:
        """Pydantic ì„¤ì • í´ë˜ìŠ¤ - êµ¬ì„± ì˜ˆì œ ì •ì˜"""
        schema_extra = {
            "example": {
                "model_name": "gpt-5-mini-2025-08-07",  # GPT-5-mini í„°ë³´ ëª¨ë¸ ì‚¬ìš©
                "temperature": 0.3,  # ë‚®ì€ ì°½ì˜ì„±ìœ¼ë¡œ ì¼ê´€ëœ ë¶„ì„
                "max_retrievals": 50,  # ìµœëŒ€ 20ê°œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
                "enable_caching": True  # ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
            }
        }


class BaseAgent(ABC):
    """
    ëª¨ë“  BlindInsight AI ì—ì´ì „íŠ¸ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
    
    ğŸ¯ ì œê³µ ê¸°ëŠ¥:
    - RAG ê¸°ë°˜ ì§€ì‹ ê²€ìƒ‰: ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
    - LLM ìƒí˜¸ì‘ìš©: OpenAI GPT ëª¨ë¸ì„ í†µí•œ ë¶„ì„
    - MCP ì„œë¹„ìŠ¤ í˜¸ì¶œ: ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ì—°ë™
    - ê²°ê³¼ ê²€ì¦: í’ˆì§ˆ ê´€ë¦¬ ë° ì„±ëŠ¥ ì¶”ì 
    
    ğŸ—ï¸ ìƒì†ë°›ëŠ” ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤:
    - CultureAnalysisAgent: íšŒì‚¬ ë¬¸í™” ë¶„ì„
    - CompensationAnalysisAgent: ì—°ë´‰ ë° ë³µë¦¬í›„ìƒ ë¶„ì„
    - GrowthStabilityAgent: ì„±ì¥ì„± ë° ì•ˆì •ì„± ë¶„ì„
    - CareerPathAgent: ì»¤ë¦¬ì–´ ê²½ë¡œ ë¶„ì„
    """
    
    def __init__(
        self,
        name: str,
        config: Optional[AgentConfig] = None,
        tools: Optional[List[Tool]] = None
    ):
        """
        BaseAgent ì´ˆê¸°í™” ë©”ì„œë“œ

        Args:
            name: ì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "culture_analysis")
            config: ì—ì´ì „íŠ¸ ì„¤ì • (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
            tools: ì¶”ê°€ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        """
        self.name = name  # ì—ì´ì „íŠ¸ ì‹ë³„ì
        self.config = config or AgentConfig()  # ì„¤ì • (ê¸°ë³¸ê°’ ë˜ëŠ” ì»¤ìŠ¤í…€)
        self.tools = tools or []  # ë„êµ¬ ëª©ë¡ ì´ˆê¸°í™”

        # ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ëª… ê²°ì •
        model_name = self._get_agent_model_name()

        # LLM ëª¨ë¸ ì´ˆê¸°í™” - OpenAI ChatGPT
        self.llm = ChatOpenAI(
            model=model_name,  # ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ëª… ì„¤ì •
            temperature=self.config.temperature,  # ì°½ì˜ì„± ìˆ˜ì¤€
            max_tokens=self.config.max_tokens,  # ìµœëŒ€ í† í° ìˆ˜
            timeout=self.config.timeout,  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            api_key=settings.openai_api_key  # API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        )
        
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ë¥¼ ìœ„í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ ë§ˆì´ê·¸ë ˆì´ì…˜)
        self.chat_history: List[Union[AIMessage, HumanMessage]] = []
        
        # RAG ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        self.knowledge_base = KnowledgeBase()
        self.rag_retriever = RAGRetriever(
            vector_store=self.knowledge_base.vector_store,
            keyword_threshold=self.config.keyword_match_threshold
        )
        
        # MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì„¤ì •)
        self.mcp_clients = {}
        
        # ì„±ëŠ¥ ì¶”ì  ë³€ìˆ˜ ì´ˆê¸°í™”
        self._execution_count = 0  # ì´ ì‹¤í–‰ íšŸìˆ˜
        self._total_execution_time = 0.0  # ì´ ì‹¤í–‰ ì‹œê°„
        self._success_count = 0  # ì„±ê³µ ì‹¤í–‰ íšŸìˆ˜

    def _get_agent_model_name(self) -> str:
        """
        ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ëª… ê²°ì •

        ìš°ì„ ìˆœìœ„:
        1. configì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ëœ ëª¨ë¸ëª…
        2. ì—ì´ì „íŠ¸ë³„ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        3. ê¸°ë³¸ ì—ì´ì „íŠ¸ ëª¨ë¸
        4. í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’

        Returns:
            ì‚¬ìš©í•  ëª¨ë¸ëª…
        """
        # 1. configì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°
        if hasattr(self.config, 'model_name') and self.config.model_name != "gpt-4o-mini-2024-07-18":
            return self.config.model_name

        # 2. ì—ì´ì „íŠ¸ë³„ í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
        agent_model_map = {
            "salary_benefits_agent": settings.salary_benefits_agent_model,
            "company_culture_agent": settings.company_culture_agent_model,
            "work_life_balance_agent": settings.work_life_balance_agent_model,
            "management_agent": settings.management_agent_model,
            "career_growth_agent": settings.career_growth_agent_model,
            "quality_evaluator_agent": settings.quality_evaluator_agent_model,
        }

        if self.name in agent_model_map:
            return agent_model_map[self.name]

        # 3. ê¸°ë³¸ ì—ì´ì „íŠ¸ ëª¨ë¸
        return settings.default_agent_model
    
    def add_message(self, message: Union[HumanMessage, AIMessage]):
        """ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
        self.chat_history.append(message)
    
    @abstractmethod
    async def execute(
        self, 
        query: str, 
        context: Optional[Dict[str, Any]] = None,
        user_profile: Optional[UserProfile] = None
    ) -> AgentResult:
        """
        ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì‹¤í–‰í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„ í•„ìˆ˜)
        
        ğŸ¯ ì£¼ìš” ì—­í• :
        - ì‚¬ìš©ì ì§ˆì˜ì— ëŒ€í•œ ë¶„ì„ ìˆ˜í–‰
        - RAGì™€ MCPë¥¼ í™œìš©í•œ ë°ì´í„° ê²€ìƒ‰ ë° ì²˜ë¦¬
        - LLMì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì‘ë‹µ êµ¬ì„±
        
        Args:
            query: ë¶„ì„í•  ì£¼ìš” ì§ˆì˜ (ì˜ˆ: "ë„¤ì´ë²„ íšŒì‚¬ ë¬¸í™”ëŠ” ì–´ë•Œ?")
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (íšŒì‚¬ëª…, ì§ë¬´ ë“±)
            user_profile: ê°œì¸í™” ë¶„ì„ì„ ìœ„í•œ ì‚¬ìš©ì í”„ë¡œí•„
            
        Returns:
            AgentResult: ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ í‘œì¤€í™”ëœ ê²°ê³¼ ê°ì²´
        """
        pass
    
    async def execute_as_supervisor_tool(
        self,
        user_question: str,
        supervisor_prompt: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ìƒˆë¡œìš´ Supervisor Tool ì›Œí¬í”Œë¡œìš°:
        1. ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° RAG ê²€ìƒ‰
        2. ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        3. Supervisor í”„ë¡¬í”„íŠ¸ + RAG ê²°ê³¼ë¡œ LLM ì‘ë‹µ ìƒì„±
        4. AI í’ˆì§ˆ í‰ê°€ (í–¥í›„ êµ¬í˜„)
        
        Args:
            user_question: ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸
            supervisor_prompt: Supervisorê°€ ìƒì„±í•œ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            str: ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ í…ìŠ¤íŠ¸
        """
        try:
            print(f"[{self.name}] ===== execute_as_supervisor_tool ì‹œì‘ =====")
            print(f"[{self.name}] ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")
            print(f"[{self.name}] Supervisor í”„ë¡¬í”„íŠ¸ ì¡´ì¬: {bool(supervisor_prompt)}")
            if supervisor_prompt:
                print(f"[{self.name}] Supervisor í”„ë¡¬í”„íŠ¸: {supervisor_prompt[:200]}...")
            print(f"[{self.name}] ì»¨í…ìŠ¤íŠ¸: {context}")
            
            # 1. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ í•„í„° ì‚¬ìš©
            frontend_company = context.get("company_filter") if context else None
            frontend_year = context.get("year_filter") if context else None
            frontend_content_type = context.get("content_type") if context else None

            print(f"[{self.name}] í”„ë¡ íŠ¸ì—”ë“œ í•„í„° - íšŒì‚¬: {frontend_company}, ì—°ë„: {frontend_year}, ì½˜í…ì¸ íƒ€ì…: {frontend_content_type}")

            # 2. RAG ê²€ìƒ‰ ìˆ˜í–‰ (ë‹¨ìˆœí™”)
            print(f"[{self.name}] RAG ê²€ìƒ‰ ì‹œì‘...")
            rag_documents = await self._perform_rag_search(
                user_question=user_question,
                company_filter=frontend_company,
                year_filter=frontend_year,
                content_type_filter=frontend_content_type,
                context=context
            )
            
            # 3. ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not rag_documents:
                print(f"[{self.name}] RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                company_text = frontend_company or "í•´ë‹¹ íšŒì‚¬"
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{company_text}'ì— ëŒ€í•œ {self.name} ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            print(f"[{self.name}] RAG ê²€ìƒ‰ ì™„ë£Œ: {len(rag_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
            for i, doc in enumerate(rag_documents[:3]):
                content_preview = doc.page_content[:150].replace('\n', ' ')
                print(f"[{self.name}] ë¬¸ì„œ {i+1}: {content_preview}...")
            
            # 4. Supervisor í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
            if supervisor_prompt and supervisor_prompt.strip():
                final_prompt = supervisor_prompt
                print(f"[{self.name}] Supervisor ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            else:
                # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
                final_prompt = self._generate_default_prompt(user_question, frontend_company)
                print(f"[{self.name}] ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            
            print(f"[{self.name}] ìµœì¢… í”„ë¡¬í”„íŠ¸: {final_prompt[:300]}...")
            
            # 5. LLM ì‘ë‹µ ìƒì„± (RAG ë¬¸ì„œ + í”„ë¡¬í”„íŠ¸)
            print(f"[{self.name}] LLM ì‘ë‹µ ìƒì„± ì‹œì‘...")
            response = await self.generate_response(
                prompt=final_prompt,
                context_documents=rag_documents,
                temperature=0.7,
                max_tokens=4000
            )
            
            print(f"[{self.name}] LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response) if response else 0}ì")
            if response:
                print(f"[{self.name}] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response[:200]}...")
            
            # 6. ì‘ë‹µ í›„ì²˜ë¦¬
            if response and response.strip():
                final_response = response.strip()
                print(f"[{self.name}] ===== execute_as_supervisor_tool ì™„ë£Œ =====")
                return final_response
            else:
                print(f"[{self.name}] ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. {self.name}ì—ì„œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            print(f"[{self.name}] execute_as_supervisor_tool ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _perform_rag_search(
        self,
        user_question: str,
        company_filter: Optional[str] = None,
        year_filter: Optional[str] = None,
        content_type_filter: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Document]:
        """RAG ê²€ìƒ‰ ìˆ˜í–‰ - í”„ë¡ íŠ¸ì—”ë“œ í•„í„° ì§ì ‘ ì‚¬ìš©"""
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            search_query = user_question
            
            # ì—ì´ì „íŠ¸ë³„ ì „ë¬¸ ì»¬ë ‰ì…˜ ì‚¬ìš©
            collections = getattr(self, 'target_collections', ['general'])
            
            print(f"[{self.name}] ê²€ìƒ‰ ì¿¼ë¦¬: '{search_query}'")
            print(f"[{self.name}] ëŒ€ìƒ ì»¬ë ‰ì…˜: {collections}")
            print(f"[{self.name}] íšŒì‚¬ í•„í„°: {company_filter}")
            print(f"[{self.name}] ì—°ë„ í•„í„°: {year_filter}")
            print(f"[{self.name}] ì½˜í…ì¸ íƒ€ì… í•„í„°: {content_type_filter}")

            # RAG ê²€ìƒ‰ ìˆ˜í–‰ (í”„ë¡ íŠ¸ì—”ë“œ í•„í„° ì§ì ‘ ì‚¬ìš©)
            documents = await self.retrieve_knowledge(
                query=search_query,
                collections=collections,
                company_name=company_filter,
                year_filter=year_filter,
                content_type_filter=content_type_filter,
                k=15  # ì¢€ ë” ë§ì€ ë¬¸ì„œ ê²€ìƒ‰
            )
            
            print(f"[{self.name}] RAG ê²€ìƒ‰ ê²°ê³¼: {len(documents)}ê°œ ë¬¸ì„œ")
            return documents
            
        except Exception as e:
            print(f"[{self.name}] RAG ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def _generate_default_prompt(self, user_question: str, company_name: Optional[str]) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (Supervisor í”„ë¡¬í”„íŠ¸ê°€ ì—†ì„ ë•Œ)"""
        company_text = company_name or "í•´ë‹¹ íšŒì‚¬"
        
        return f"""
ë‹¤ìŒì€ {company_text}ì— ëŒ€í•œ ì‹¤ì œ ë¦¬ë·° ë°ì´í„°ì…ë‹ˆë‹¤.
ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ "{user_question}"ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ì‹¤ì œ ë¦¬ë·° ë°ì´í„°ì— ê·¼ê±°í•œ êµ¬ì²´ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€
2. ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜•ìˆê²Œ ì œì‹œ
3. ì‚¬ìš©ìê°€ ì˜ì‚¬ê²°ì •ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê²Œ ì„¤ëª…
4. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±

ë¦¬ë·° ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
    
    def _format_supervisor_response(self, result: Dict[str, Any], original_question: str) -> str:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            # ê²°ê³¼ì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
            if "summary" in result:
                return result["summary"]
            elif "final_summary" in result:
                return result["final_summary"]
            elif "analysis" in result:
                return result["analysis"]
            elif isinstance(result, str):
                return result
            else:
                # êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                parts = []
                
                if "strengths" in result:
                    strengths = result["strengths"]
                    if isinstance(strengths, dict):
                        pros = strengths.get("pros", [])
                        if pros:
                            parts.append("**ì¥ì :**")
                            for pro in pros[:3]:  # ìƒìœ„ 3ê°œë§Œ
                                parts.append(f"â€¢ {pro}")
                
                if "weaknesses" in result:
                    weaknesses = result["weaknesses"]
                    if isinstance(weaknesses, dict):
                        cons = weaknesses.get("cons", [])
                        if cons:
                            parts.append("\n**ë‹¨ì :**")
                            for con in cons[:3]:  # ìƒìœ„ 3ê°œë§Œ
                                parts.append(f"â€¢ {con}")
                
                return "\n".join(parts) if parts else f"{self.name}ì˜ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                
        except Exception:
            return f"{self.name}ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    async def retrieve_knowledge(
        self,
        query: str,
        collections: List[str] = None,
        company_name: Optional[str] = None,
        content_type_filter: Optional[str] = None,  # "pros", "cons"
        position_filter: Optional[str] = None,  # ì§ë¬´ í•„í„° (ì˜ˆ: "IT ë””ìì´ë„ˆ")
        year_filter: Optional[str] = None,  # ì—°ë„ í•„í„° (ì˜ˆ: "2024")
        k: int = None
    ) -> List[Document]:
        """
        ğŸ” RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ (ë©€í‹° ì»¬ë ‰ì…˜ ì§€ì›)
        
        ğŸ—ï¸ RAG ê²€ìƒ‰ ê³¼ì •:
        1. ì¿¼ë¦¬ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ (OpenAI text-embedding-3-small)
        2. ì§€ì •ëœ ì»¬ë ‰ì…˜ë“¤ì—ì„œ ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰
        3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ë¬¸ì„œë§Œ í•„í„°ë§
        4. íšŒì‚¬ë³„ í•„í„°ë§ ì ìš© (ì„ íƒì )
        5. ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜ (ì¤‘ë³µ ì œê±°)
        
        ğŸ“ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜:
        - company_culture: íšŒì‚¬ ë¬¸í™” ë¦¬ë·° (ê¸°ì—…ë¬¸í™”, ì¡°ì§ë¬¸í™”)
        - work_life_balance: ì›Œë¼ë°¸ ê´€ë ¨ (ê·¼ë¬´ì‹œê°„, ì•¼ê·¼, íœ´ê°€)
        - management: ê²½ì˜ì§„/ê´€ë¦¬ ê´€ë ¨ (ìƒì‚¬, ë¦¬ë”ì‹­, ì˜ì‚¬ê²°ì •)
        - salary_benefits: ì—°ë´‰ ë° ë³µë¦¬í›„ìƒ (ê¸‰ì—¬, ë³´ë„ˆìŠ¤, ë³µì§€)
        - career_growth: ì»¤ë¦¬ì–´ ì„±ì¥ (ìŠ¹ì§„, êµìœ¡, ë°œì „ê¸°íšŒ)
        
        Args:
            query: ê²€ìƒ‰í•  ì§ˆë¬¸ (ì˜ˆ: "êµ¬ê¸€ ì›Œë¼ë°¸ ì–´ë•Œ?" ë˜ëŠ” í‚¤ì›Œë“œ í¬í•¨ "êµ¬ê¸€ ì›Œë¼ë°¸ ìˆ˜í‰ì  ììœ¨ì ")
            collections: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ëª©ë¡ (ì˜ˆ: ["company_culture", "general"])
            company_name: íšŒì‚¬ëª… í•„í„° (ì˜ˆ: "êµ¬ê¸€")
            content_type_filter: ë‚´ìš© íƒ€ì… í•„í„° ("pros", "cons")
            position_filter: ì§ë¬´ í•„í„° (ì˜ˆ: "IT ë””ìì´ë„ˆ")
            year_filter: ì—°ë„ í•„í„° (ì˜ˆ: "2024")
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ê°’: config.max_retrievals=20)
            
        Returns:
            List[Document]: ê´€ë ¨ ë¬¸ì„œ ëª©ë¡ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
        """
        if not self.rag_retriever:
            return []
        
        k = k or self.config.max_retrievals
        collections = collections or ["general"]
        
        try:
            filters = {}
            if company_name:
                filters["company"] = company_name
            if content_type_filter:
                filters["content_type"] = content_type_filter
            if position_filter:
                filters["position"] = position_filter
            if year_filter:
                filters["review_year"] = year_filter
            
            print(f"[{self.name}] retrieve_knowledge - í•„í„°: {filters}")
            print(f"[{self.name}] retrieve_knowledge - ìš”ì²­ ë¬¸ì„œìˆ˜: {k}")
            
            # ë©€í‹° ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰
            all_results = []
            for collection_name in collections:
                try:
                    collection_k = k // len(collections) + 2
                    print(f"[{self.name}] '{collection_name}' ì»¬ë ‰ì…˜ì—ì„œ {collection_k}ê°œ ë¬¸ì„œ ê²€ìƒ‰...")
                    
                    search_results = await self.rag_retriever.search(
                        query=query,
                        collection_name=collection_name,
                        k=collection_k,
                        filters=filters,
                        search_type="ensemble"
                    )
                    print(f"[{self.name}] '{collection_name}' ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
                    all_results.extend(search_results)
                except Exception as e:
                    print(f"[{self.name}] '{collection_name}' ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # ì¤‘ë³µ ì œê±° ë° í•„í„°ë§
            documents = []
            seen_contents = set()
            sorted_results = sorted(all_results, key=lambda x: x.relevance_score, reverse=True)
            
            for result in sorted_results:
                content_hash = hash(result.document.page_content[:100])

                if result.relevance_score < self.config.relevance_threshold:
                    print(
                        f"relevance_score={result.relevance_score:.4f} "
                        f"threshold={self.config.relevance_threshold} "
                        f"collection={getattr(result.document, 'metadata', {}).get('collection', 'unknown')} "
                        f"preview={result.document.page_content[:50]!r}"
                    )

                if (content_hash not in seen_contents and 
                    result.relevance_score >= self.config.relevance_threshold):
                    seen_contents.add(content_hash)
                    documents.append(result.document)
                    if len(documents) >= k:
                        break
            
            return documents
            
        except Exception:
            return []
    
    async def call_mcp_service(
        self, 
        service_name: str, 
        method: str, 
        params: Dict[str, Any]
    ) -> Any:
        """
        ğŸŒ MCP(Model Context Protocol) ì„œë¹„ìŠ¤ í˜¸ì¶œ
        
        ğŸ”— MCP ì„œë¹„ìŠ¤ ì¢…ë¥˜:
        - BlindDataProvider: Blind.com ë¦¬ë·° ë° ì—°ë´‰ ì •ë³´
        - JobSiteProvider: ì±„ìš© ì‚¬ì´íŠ¸ ê³µê³  ì •ë³´
        - SalaryDataProvider: ì—°ë´‰ ë²¤ì¹˜ë§ˆí‚¹ ë°ì´í„°
        - CompanyNewsProvider: íšŒì‚¬ ë‰´ìŠ¤ ë° ë™í–¥
        
        ğŸš€ í˜¸ì¶œ ê³¼ì •:
        1. ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        2. ë¹„ë™ê¸° API í˜¸ì¶œ ì‹¤í–‰
        3. ì‘ë‹µ ë°ì´í„° ë°˜í™˜
        4. ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥ í›„ None ë°˜í™˜
        
        Args:
            service_name: MCP ì„œë¹„ìŠ¤ ì´ë¦„ (ì˜ˆ: 'blind_data')
            method: í˜¸ì¶œí•  ë©”ì„œë“œ (ì˜ˆ: 'get_company_reviews')
            params: ë©”ì„œë“œ íŒŒë¼ë¯¸í„° (ì˜ˆ: {'company': 'ë„¤ì´ë²„', 'limit': 10})
            
        Returns:
            Any: ì„œë¹„ìŠ¤ ì‘ë‹µ ë°ì´í„° (ì„œë¹„ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ í˜•íƒœ)
        """
        if service_name not in self.mcp_clients:
            raise ValueError(f"MCP ì„œë¹„ìŠ¤ '{service_name}'ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        try:
            client = self.mcp_clients[service_name]
            return await client.call(method, params)
        except Exception:
            return None
    
    async def generate_response(
        self, 
        prompt: str, 
        context_documents: List[Document] = None,
        **kwargs
    ) -> str:
        """
        ğŸ¤– LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± (RAG + LLM í†µí•©) ê³ ì •í˜•
        
        ğŸ”„ ìƒì„± ê³¼ì •:
        1. RAG ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        2. í”„ë¡¬í”„íŠ¸ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        3. OpenAI GPT ëª¨ë¸ë¡œ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±
        4. ìƒì„±ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
        
        ğŸ’¡ ì»¨í…ìŠ¤íŠ¸ í™œìš©:
        - ìµœëŒ€ 5ê°œ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš© (í† í° ì œí•œ)
        - ê° ë¬¸ì„œëŠ” "Document 1:", "Document 2:" í˜•íƒœë¡œ êµ¬ì„±
        - ê²€ìƒ‰ëœ ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì •í™•í•œ ë¶„ì„ ì œê³µ
        
        Args:
            prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸ (ì˜ˆ: "ë„¤ì´ë²„ì˜ ì›Œë¼ë°¸ì„ ë¶„ì„í•´ì¤˜")
            context_documents: RAGë¡œ ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤
            **kwargs: ì¶”ê°€ LLM íŒŒë¼ë¯¸í„° (temperature, max_tokens ë“±)
            
        Returns:
            str: LLMì´ ìƒì„±í•œ ë¶„ì„ ì‘ë‹µ
        """
        if context_documents:
            context_text = "\n\n".join([
                f"Document {i+1}:\n{doc.page_content}"
                for i, doc in enumerate(context_documents[:5])
            ])
            full_prompt = f"Context:\n{context_text}\n\nQuery: {prompt}"
        else:
            full_prompt = prompt
        
        try:
            response = await self.llm.ainvoke(full_prompt, **kwargs)
            return response.content
        except Exception:
            return ""
    
    async def validate_result(
        self, 
        result: Dict[str, Any], 
        required_fields: List[str] = None
    ) -> tuple[bool, List[str]]:
        """
        ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ë©”ì„œë“œ
        
        ğŸ” ê²€ì¦ í•­ëª©:
        - í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€
        - ì‹ ë¢°ë„ ì ìˆ˜ ì„ê³„ê°’
        - ì¶œì²˜ ì •ë³´ í•„ìˆ˜ ì—¬ë¶€
        
        Args:
            result: ê²€ì¦í•  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            required_fields: í•„ìˆ˜ í•„ë“œ ëª©ë¡ (ì„ íƒì‚¬í•­)
            
        Returns:
            tuple[bool, List[str]]: (ê²€ì¦ ì„±ê³µ ì—¬ë¶€, ì˜¤ë¥˜ ëª©ë¡)
        """
        errors = []  # ê²€ì¦ ì˜¤ë¥˜ ëª©ë¡
        
        # ì¶œë ¥ ê²€ì¦ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ê²€ì¦ ê±´ë„ˆë›°ê¸°
        if not self.config.validate_outputs:
            return True, errors
        
        # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if required_fields:
            for field in required_fields:
                if field not in result:
                    errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ì„ê³„ê°’ í™•ì¸
        confidence = result.get("confidence_score", 0.0)
        if confidence < self.config.min_confidence_threshold:
            errors.append(f"ì‹ ë¢°ë„ ì ìˆ˜ {confidence}ê°€ ì„ê³„ê°’ {self.config.min_confidence_threshold}ë³´ë‹¤ ë‚®ìŒ")
        
        # ì¶œì²˜ ì •ë³´ í•„ìˆ˜ ì—¬ë¶€ í™•ì¸
        if self.config.require_sources and not result.get("sources"):
            errors.append("ì¶œì²˜ ì •ë³´ê°€ í•„ìˆ˜ì´ì§€ë§Œ ì œê³µë˜ì§€ ì•ŠìŒ")
        
        return len(errors) == 0, errors  # ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ True, ìˆìœ¼ë©´ False
    
    def update_performance_metrics(self, execution_time: float, success: bool) -> None:
        """
        ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë©”ì„œë“œ
        
        Args:
            execution_time: ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
            success: ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€
        """
        self._execution_count += 1  # ì´ ì‹¤í–‰ íšŸìˆ˜ ì¦ê°€
        self._total_execution_time += execution_time  # ì´ ì‹¤í–‰ ì‹œê°„ ëˆ„ì 
        if success:
            self._success_count += 1  # ì„±ê³µ íšŸìˆ˜ ì¦ê°€
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ì„±ëŠ¥ í†µê³„ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
        
        Returns:
            Dict[str, Any]: ì„±ëŠ¥ í†µê³„ ì •ë³´
            - execution_count: ì´ ì‹¤í–‰ íšŸìˆ˜
            - success_rate: ì„±ê³µë¥  (0.0~1.0)
            - average_execution_time: í‰ê·  ì‹¤í–‰ ì‹œê°„
            - total_execution_time: ì´ ì‹¤í–‰ ì‹œê°„
        """
        # ì‹¤í–‰ ê¸°ë¡ì´ ì—†ëŠ” ê²½ìš°
        if self._execution_count == 0:
            return {
                "execution_count": 0,
                "success_rate": 0.0,
                "average_execution_time": 0.0
            }
        
        # ì„±ëŠ¥ í†µê³„ ê³„ì‚° ë° ë°˜í™˜
        return {
            "execution_count": self._execution_count,  # ì´ ì‹¤í–‰ íšŸìˆ˜
            "success_rate": self._success_count / self._execution_count,  # ì„±ê³µë¥ 
            "average_execution_time": self._total_execution_time / self._execution_count,  # í‰ê·  ì‹¤í–‰ ì‹œê°„
            "total_execution_time": self._total_execution_time  # ì´ ì‹¤í–‰ ì‹œê°„
        }
    
    async def _execute_with_error_handling(
        self,
        execution_func,
        *args,
        **kwargs
    ) -> AgentResult:
        """
        í¬ê´„ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬ì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ
        
        ğŸ›¡ï¸ ì£¼ìš” ê¸°ëŠ¥:
        - ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë° ì¶”ì 
        - ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬
        - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬
        - ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
        
        Args:
            execution_func: ì‹¤í–‰í•  í•¨ìˆ˜
            *args: ìœ„ì¹˜ ì¸ìë“¤
            **kwargs: í‚¤ì›Œë“œ ì¸ìë“¤
            
        Returns:
            AgentResult: ì‹¤í–‰ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ ê²°ê³¼ ê°ì²´
        """
        start_time = time.time()  # ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        
        try:
            # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
            result = await execution_func(*args, **kwargs)
            execution_time = time.time() - start_time  # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            
            # ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ê²€ì¦ ìˆ˜í–‰
            if isinstance(result, dict):
                is_valid, validation_errors = await self.validate_result(result)
                if not is_valid:
                    # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì‹¤íŒ¨ ê²°ê³¼ ë°˜í™˜
                    self.update_performance_metrics(execution_time, False)
                    return AgentResult(
                        agent_name=self.name,
                        success=False,
                        error_message=f"ê²€ì¦ ì‹¤íŒ¨: {', '.join(validation_errors)}",
                        execution_time=execution_time
                    )
            
            # ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸ (ì„±ê³µ)
            self.update_performance_metrics(execution_time, True)
            
            # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
            return AgentResult(
                agent_name=self.name,
                success=True,
                result=result if isinstance(result, dict) else {"output": result},
                execution_time=execution_time,
                confidence_score=result.get("confidence_score", 1.0) if isinstance(result, dict) else 1.0
            )
            
        except Exception as e:
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ì²˜ë¦¬
            execution_time = time.time() - start_time
            self.update_performance_metrics(execution_time, False)
            
            return AgentResult(
                agent_name=self.name,
                success=False,
                error_message=str(e),
                execution_time=execution_time
            )


class AgentOrchestrator:
    """
    ë³µì¡í•œ ë¶„ì„ ì‘ì—…ì„ ìœ„í•´ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í´ë˜ìŠ¤
    
    ğŸ¼ ì£¼ìš” ì—­í• :
    - ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì˜ ë“±ë¡ ë° ê´€ë¦¬
    - ìˆœì°¨ì /ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
    - ì‹¤í–‰ ê¸°ë¡ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    - ê²°ê³¼ ì§‘ê³„ ë° ë¶„ì„
    """
    
    def __init__(self):
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        self.agents: Dict[str, BaseAgent] = {}  # ë“±ë¡ëœ ì—ì´ì „íŠ¸ë“¤
        self.execution_history: List[Dict[str, Any]] = []  # ì‹¤í–‰ ê¸°ë¡
    
    def register_agent(self, agent: BaseAgent) -> None:
        """
        ì—ì´ì „íŠ¸ë¥¼ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ë“±ë¡
        
        Args:
            agent: ë“±ë¡í•  BaseAgent ì¸ìŠ¤í„´ìŠ¤
        """
        self.agents[agent.name] = agent
    
    def get_agent(self, name: str) -> Optional[BaseAgent]:
        """
        ì´ë¦„ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì¡°íšŒ
        
        Args:
            name: ì°¾ì„ ì—ì´ì „íŠ¸ ì´ë¦„
            
        Returns:
            Optional[BaseAgent]: ì°¾ì€ ì—ì´ì „íŠ¸ ë˜ëŠ” None
        """
        return self.agents.get(name)
    
    async def execute_agents(
        self,
        agent_names: List[str],
        query: str,
        context: Optional[Dict[str, Any]] = None,
        parallel: bool = True
    ) -> Dict[str, AgentResult]:
        """
        Execute multiple agents.
        
        Args:
            agent_names: List of agent names to execute
            query: Query to pass to agents
            context: Additional context
            parallel: Execute agents in parallel if True
            
        Returns:
            Dictionary mapping agent names to their results
        """
        
        # ìœ íš¨í•œ ì—ì´ì „íŠ¸ë§Œ í•„í„°ë§
        valid_agents = [
            (name, self.agents[name]) 
            for name in agent_names 
            if name in self.agents
        ]
        
        # ìœ íš¨í•œ ì—ì´ì „íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if not valid_agents:
            return {}
        
        start_time = time.time()  # ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        
        if parallel:
            # ë³‘ë ¬ ì‹¤í–‰ ëª¨ë“œ
            tasks = [
                agent.execute(query, context)
                for _, agent in valid_agents
            ]
            
            # ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì‹œ ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì²˜ë¦¬
            agent_results = {}
            for (name, _), result in zip(valid_agents, results):
                if isinstance(result, Exception):
                    # ì˜ˆì™¸ ë°œìƒí•œ ì—ì´ì „íŠ¸ëŠ” ì‹¤íŒ¨ ê²°ê³¼ë¡œ ì²˜ë¦¬
                    agent_results[name] = AgentResult(
                        agent_name=name,
                        success=False,
                        error_message=str(result),
                        execution_time=time.time() - start_time
                    )
                else:
                    agent_results[name] = result
        
        else:
            # ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ
            agent_results = {}
            for name, agent in valid_agents:
                result = await agent.execute(query, context)
                agent_results[name] = result
        
        # ì‹¤í–‰ ê¸°ë¡ ì €ì¥
        total_time = time.time() - start_time
        self.execution_history.append({
            "timestamp": datetime.now(),  # ì‹¤í–‰ ì‹œê°„
            "agent_names": agent_names,  # ì‹¤í–‰ëœ ì—ì´ì „íŠ¸ ëª©ë¡
            "parallel": parallel,  # ì‹¤í–‰ ëª¨ë“œ
            "total_time": total_time,  # ì´ ì‹¤í–‰ ì‹œê°„
            "success_count": sum(1 for r in agent_results.values() if r.success),  # ì„±ê³µ íšŸìˆ˜
            "total_agents": len(agent_results)  # ì´ ì—ì´ì „íŠ¸ ìˆ˜
        })
        
        return agent_results
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """
        ë“±ë¡ëœ ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: ì„±ëŠ¥ ìš”ì•½ ì •ë³´
            - agent_stats: ê° ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ í†µê³„
            - orchestrator_stats: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì „ì²´ í†µê³„
        """
        # ê° ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘
        agent_stats = {
            name: agent.get_performance_stats()
            for name, agent in self.agents.items()
        }
        
        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì „ì²´ í†µê³„ ê³„ì‚°
        orchestrator_stats = {
            "total_orchestrations": len(self.execution_history),  # ì´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íšŸìˆ˜
            "average_orchestration_time": (
                sum(h["total_time"] for h in self.execution_history) / len(self.execution_history)
                if self.execution_history else 0.0  # í‰ê·  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œê°„
            )
        }
        
        return {
            "agent_stats": agent_stats,  # ì—ì´ì „íŠ¸ë³„ í†µê³„
            "orchestrator_stats": orchestrator_stats  # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í†µê³„
        }


# ì—ì´ì „íŠ¸ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
def create_agent(agent_type: str, config: Optional[AgentConfig] = None) -> BaseAgent:
    """
    íƒ€ì…ë³„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜
    
    ğŸ­ ì§€ì›í•˜ëŠ” ì—ì´ì „íŠ¸ íƒ€ì…:
    - culture: íšŒì‚¬ ë¬¸í™” ë¶„ì„ ì—ì´ì „íŠ¸
    - compensation: ì—°ë´‰ ë° ë³µë¦¬í›„ìƒ ë¶„ì„ ì—ì´ì „íŠ¸  
    - growth: ì„±ì¥ì„± ë° ì•ˆì •ì„± ë¶„ì„ ì—ì´ì „íŠ¸
    - career: ì»¤ë¦¬ì–´ ê²½ë¡œ ë¶„ì„ ì—ì´ì „íŠ¸
    
    Args:
        agent_type: ìƒì„±í•  ì—ì´ì „íŠ¸ íƒ€ì… (culture/compensation/growth/career)
        config: ì—ì´ì „íŠ¸ ì„¤ì • (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
        
    Returns:
        BaseAgent: ì„¤ì •ëœ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        
    Raises:
        ValueError: ì•Œë ¤ì§€ì§€ ì•Šì€ ì—ì´ì „íŠ¸ íƒ€ì…ì¸ ê²½ìš°
    """
    
    # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œ import
    # ìƒˆë¡œìš´ ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ë§Œ import
    from .company_culture_agent import CompanyCultureAgent
    from .work_life_balance_agent import WorkLifeBalanceAgent
    from .management_agent import ManagementAgent
    from .salary_benefits_agent import SalaryBenefitsAgent
    from .career_growth_agent import CareerGrowthAgent
    
    # ì—ì´ì „íŠ¸ íƒ€ì…ê³¼ í´ë˜ìŠ¤ ë§¤í•‘ (ìƒˆë¡œìš´ ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤)
    agent_classes = {
        # ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ (ê° ì»¬ë ‰ì…˜ë³„ + general)
        "company_culture": CompanyCultureAgent,  # ê¸°ì—…ë¬¸í™” ì „ë¬¸
        "work_life_balance": WorkLifeBalanceAgent,  # ì›Œë¼ë°¸ ì „ë¬¸
        "management": ManagementAgent,  # ê²½ì˜ì§„ ì „ë¬¸
        "salary_benefits": SalaryBenefitsAgent,  # ì—°ë´‰/ë³µì§€ ì „ë¬¸
        "career_growth": CareerGrowthAgent,  # ì»¤ë¦¬ì–´ ì„±ì¥ ì „ë¬¸
        
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
        "culture": CompanyCultureAgent,  # ê¸°ì¡´ culture -> company_culture
        "compensation": SalaryBenefitsAgent,  # ê¸°ì¡´ compensation -> salary_benefits
        "growth": CareerGrowthAgent,  # ê¸°ì¡´ growth -> career_growth  
        "career": CareerGrowthAgent  # ê¸°ì¡´ career -> career_growth
    }
    
    # ì§€ì›ë˜ì§€ ì•ŠëŠ” íƒ€ì… ì²´í¬
    if agent_type not in agent_classes:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸ íƒ€ì…: {agent_type}")
    
    # ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ë°˜í™˜
    return agent_classes[agent_type](config=config)


def get_agent_by_type(agent_type: str) -> Type[BaseAgent]:
    """
    íƒ€ì…ë³„ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        agent_type: ì¡°íšŒí•  ì—ì´ì „íŠ¸ íƒ€ì…
        
    Returns:
        Type[BaseAgent]: ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ (ì—†ìœ¼ë©´ None)
    """
    
    # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œ import
    # ìƒˆë¡œìš´ ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ë§Œ import
    from .company_culture_agent import CompanyCultureAgent
    from .work_life_balance_agent import WorkLifeBalanceAgent
    from .management_agent import ManagementAgent
    from .salary_benefits_agent import SalaryBenefitsAgent
    from .career_growth_agent import CareerGrowthAgent
    
    # ì—ì´ì „íŠ¸ íƒ€ì…ê³¼ í´ë˜ìŠ¤ ë§¤í•‘ (ìƒˆë¡œìš´ ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤)
    agent_classes = {
        # ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ (ê° ì»¬ë ‰ì…˜ë³„ + general)
        "company_culture": CompanyCultureAgent,  # ê¸°ì—…ë¬¸í™” ì „ë¬¸ í´ë˜ìŠ¤
        "work_life_balance": WorkLifeBalanceAgent,  # ì›Œë¼ë°¸ ì „ë¬¸ í´ë˜ìŠ¤
        "management": ManagementAgent,  # ê²½ì˜ì§„ ì „ë¬¸ í´ë˜ìŠ¤
        "salary_benefits": SalaryBenefitsAgent,  # ì—°ë´‰/ë³µì§€ ì „ë¬¸ í´ë˜ìŠ¤
        "career_growth": CareerGrowthAgent,  # ì»¤ë¦¬ì–´ ì„±ì¥ ì „ë¬¸ í´ë˜ìŠ¤
        
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
        "culture": CompanyCultureAgent,  # ê¸°ì¡´ culture -> company_culture
        "compensation": SalaryBenefitsAgent,  # ê¸°ì¡´ compensation -> salary_benefits
        "growth": CareerGrowthAgent,  # ê¸°ì¡´ growth -> career_growth  
        "career": CareerGrowthAgent  # ê¸°ì¡´ career -> career_growth
    }
    
    return agent_classes.get(agent_type)  # í•´ë‹¹ íƒ€ì…ì˜ í´ë˜ìŠ¤ ë°˜í™˜ (ì—†ìœ¼ë©´ None)