"""
LangGraph ì›Œí¬í”Œë¡œìš° ê·¸ëž˜í”„ êµ¬ì„± ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - ì´ˆë³´ìž ê°€ì´ë“œ

ðŸŽ¯ StateGraphëž€?
StateGraphëŠ” LangGraphì˜ í•µì‹¬ìœ¼ë¡œ, ë…¸ë“œë“¤ ê°„ì˜ ì—°ê²°ê³¼ ì‹¤í–‰ ìˆœì„œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ê° ë…¸ë“œëŠ” í•¨ìˆ˜ì´ê³ , ì—£ì§€(Edge)ëŠ” ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²°ì„ ìž…ë‹ˆë‹¤.

ðŸ—ï¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ìš”ì†Œ:
1. StateGraph(WorkflowState): ìƒíƒœ í´ëž˜ìŠ¤ë¥¼ ì§€ì •í•˜ì—¬ ê·¸ëž˜í”„ ìƒì„±
2. add_node(): ë…¸ë“œ(í•¨ìˆ˜) ì¶”ê°€
3. add_edge(): ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²° ì •ì˜
4. set_entry_point(): ì‹œìž‘ ë…¸ë“œ ì§€ì •
5. compile(): ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ì»´íŒŒì¼

ðŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
1. ìƒˆ ë…¸ë“œ ì¶”ê°€:
   - workflow.add_node("node_name", node_function)
   - ì ì ˆí•œ ìœ„ì¹˜ì— ì—£ì§€ ì—°ê²°

2. ì‹¤í–‰ íë¦„ ë³€ê²½:
   - ì—£ì§€ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ë…¸ë“œ ì‹¤í–‰ ìˆœì„œ ë³€ê²½
   - ì¡°ê±´ë¶€ ì—£ì§€ë¡œ ë¶„ê¸° ì²˜ë¦¬ ê°€ëŠ¥

3. ë³‘ë ¬/ìˆœì°¨ ì‹¤í–‰ ì „í™˜:
   - config.enable_parallel_executionìœ¼ë¡œ ì œì–´
   - _define_workflow_edges()ì—ì„œ íë¦„ ì •ì˜

4. ì²´í¬í¬ì¸íŒ…:
   - MemorySaverë¡œ ì¤‘ê°„ ìƒíƒœ ì €ìž¥
   - ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨ ì§€ì ë¶€í„° ìž¬ì‹œìž‘ ê°€ëŠ¥
"""

import uuid
from datetime import datetime
from typing import Dict, List, Optional

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from ..models.analysis import AnalysisRequest
from ..models.user import UserProfile
from .state import WorkflowState, WorkflowConfig
from .nodes import (
    InputValidationNode, CultureAnalysisNode, CompensationAnalysisNode,
    GrowthAnalysisNode, CareerAnalysisNode, ParallelAnalysisNode,
    SynthesisNode, ReportGenerationNode
)


class BlindInsightWorkflow:
    """
    ðŸŽ¯ BlindInsight AI ë¶„ì„ ì‹œìŠ¤í…œì˜ ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    
    LangGraph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ì—¬ ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ê³ 
    ì¢…í•©ì ì¸ ê¸°ì—… ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ðŸ—ï¸ ì›Œí¬í”Œë¡œìš° ì•„í‚¤í…ì²˜:
    
    ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ culture_analysis â†’ compensation_analysis â†’ growth_analysis â†’ career_analysis â†’ synthesis â†’ report_generation
    
    ë³‘ë ¬ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ parallel_analysis (culture + compensation + growth ë™ì‹œ ì‹¤í–‰) â†’ career_analysis â†’ synthesis â†’ report_generation
    
    ðŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
    1. ìƒˆë¡œìš´ ë¶„ì„ íƒ€ìž… ì¶”ê°€:
       - ìƒˆ ë…¸ë“œ ëž˜í¼ ë©”ì„œë“œ ì¶”ê°€ (_your_analysis_wrapper)
       - _build_workflow()ì—ì„œ ë…¸ë“œ ì¶”ê°€
       - _define_workflow_edges()ì—ì„œ ì—°ê²° ì •ì˜
    
    2. ì‹¤í–‰ ëª¨ë“œ ë³€ê²½:
       - WorkflowConfigì˜ enable_parallel_executionìœ¼ë¡œ ì œì–´
       - ë³‘ë ¬ ëª¨ë“œ: ë…ë¦½ì ì¸ ë¶„ì„ë“¤ì„ ë™ì‹œ ì‹¤í–‰í•˜ì—¬ ì†ë„ í–¥ìƒ
       - ìˆœì°¨ ëª¨ë“œ: ë‹¨ê³„ë³„ ìˆœì„œ ì‹¤í–‰ìœ¼ë¡œ ë””ë²„ê¹… ìš©ì´
    
    3. ì²´í¬í¬ì¸íŒ… í™œìš©:
       - thread_idë¡œ ì„¸ì…˜ ê´€ë¦¬
       - ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ë¶€í„° ìž¬ì‹œìž‘ ê°€ëŠ¥
       - ì§„í–‰ ìƒí™© ì¶”ì  ë° ë³µêµ¬
    """
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.config = config or WorkflowConfig()
        self.workflow_graph = None
        self.checkpointer = MemorySaver()
        self._build_workflow()
    
    def _build_workflow(self) -> None:
        """
        ðŸ—ï¸ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± - í•µì‹¬ ë©”ì„œë“œ
        
        ðŸ”„ êµ¬ì„± ìˆœì„œ:
        1. StateGraph ìƒì„± (ìƒíƒœ í´ëž˜ìŠ¤ ì§€ì •)
        2. ë…¸ë“œë“¤ ì¶”ê°€ (ê°ê° í•¨ìˆ˜ë¡œ ë“±ë¡)
        3. ì—£ì§€ë“¤ ì •ì˜ (ë…¸ë“œ ê°„ ì—°ê²°)
        4. ì§„ìž…ì  ì„¤ì • (ì‹œìž‘ ë…¸ë“œ)
        5. ì»´íŒŒì¼ (ì‹¤í–‰ ê°€ëŠ¥í•œ ê·¸ëž˜í”„ë¡œ ë³€í™˜)
        
        ðŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§• í¬ì¸íŠ¸:
        - ìƒˆ ë…¸ë“œ ì¶”ê°€: workflow.add_node("name", wrapper_function)
        - ì‹¤í–‰ ëª¨ë“œ: config.enable_parallel_executionìœ¼ë¡œ ì œì–´
        """
        
        # 1ï¸âƒ£ ì›Œí¬í”Œë¡œìš° ê·¸ëž˜í”„ ìƒì„± (ìƒíƒœ í´ëž˜ìŠ¤ ì§€ì •)
        workflow = StateGraph(WorkflowState)
        
        # 2ï¸âƒ£ ë…¸ë“œë“¤ ì¶”ê°€ - ê° ë…¸ë“œëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë“±ë¡
        workflow.add_node("input_validation", self._input_validation_wrapper)
        
        # ðŸ’¡ ì‹¤í–‰ ëª¨ë“œì— ë”°ë¥¸ ë…¸ë“œ êµ¬ì„±
        if self.config.enable_parallel_execution:
            # ðŸš€ ë³‘ë ¬ ì‹¤í–‰: culture, compensation, growthë¥¼ í•œ ë²ˆì—
            workflow.add_node("parallel_analysis", self._parallel_analysis_wrapper)
        else:
            # ðŸ”„ ìˆœì°¨ ì‹¤í–‰: ê° ë¶„ì„ì„ ë‹¨ê³„ì ìœ¼ë¡œ
            workflow.add_node("culture_analysis", self._culture_analysis_wrapper)
            workflow.add_node("compensation_analysis", self._compensation_analysis_wrapper)
            workflow.add_node("growth_analysis", self._growth_analysis_wrapper)
        
        # ðŸŽ¯ ê³µí†µ ë…¸ë“œë“¤ (ì‹¤í–‰ ëª¨ë“œì™€ ë¬´ê´€)
        workflow.add_node("career_analysis", self._career_analysis_wrapper)
        workflow.add_node("synthesis", self._synthesis_wrapper)
        workflow.add_node("report_generation", self._report_generation_wrapper)
        
        # ðŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆ ë…¸ë“œ ì¶”ê°€ ì˜ˆì‹œ
        # workflow.add_node("risk_analysis", self._risk_analysis_wrapper)
        
        # 3ï¸âƒ£ ì›Œí¬í”Œë¡œìš° ì—°ê²° ì •ì˜ (ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
        self._define_workflow_edges(workflow)
        
        # 4ï¸âƒ£ ì§„ìž…ì  ì„¤ì • (ì²« ë²ˆì§¸ë¡œ ì‹¤í–‰ë  ë…¸ë“œ)
        workflow.set_entry_point("input_validation")
        
        # 5ï¸âƒ£ ì»´íŒŒì¼ - ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ë³€í™˜ (ì²´í¬í¬ì¸íŒ… í¬í•¨)
        self.workflow_graph = workflow.compile(checkpointer=self.checkpointer)
    
    def _define_workflow_edges(self, workflow: StateGraph) -> None:
        """
        ðŸ”— ì›Œí¬í”Œë¡œìš° ì—£ì§€(ì—°ê²°) ì •ì˜ - ë…¸ë“œ ê°„ ì‹¤í–‰ ìˆœì„œ ê²°ì •
        
        ðŸ’¡ ì—£ì§€(Edge)ì˜ ê°œë…:
        - workflow.add_edge(A, B): A ë…¸ë“œ ì™„ë£Œ í›„ B ë…¸ë“œ ì‹¤í–‰
        - END: ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ ì§€ì 
        - ì—£ì§€ ìˆœì„œë¥¼ ë°”ê¾¸ë©´ ì‹¤í–‰ íë¦„ì´ ë³€ê²½ë¨
        
        ðŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
        1. ìƒˆ ë…¸ë“œ ì‚½ìž…: ê¸°ì¡´ ì—£ì§€ ì œê±° í›„ ìƒˆ ì—£ì§€ ì¶”ê°€
           ì˜ˆ: A -> C ì‚¬ì´ì— B ì‚½ìž…
           ê¸°ì¡´: workflow.add_edge(A, C)
           ë³€ê²½: workflow.add_edge(A, B) + workflow.add_edge(B, C)
        
        2. ì¡°ê±´ë¶€ ë¶„ê¸°: ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ì—°ê²°
        3. ë³‘ë ¬ vs ìˆœì°¨: ì„¤ì •ì— ë”°ë¼ ë‹¤ë¥¸ íë¦„ êµ¬ì„±
        """
        
        if self.config.enable_parallel_execution:
            # ðŸš€ ë³‘ë ¬ ì‹¤í–‰ íë¦„
            # input_validation â†’ parallel_analysis â†’ career_analysis â†’ synthesis â†’ report_generation â†’ END
            workflow.add_edge("input_validation", "parallel_analysis")
            workflow.add_edge("parallel_analysis", "career_analysis")
        else:
            # ðŸ”„ ìˆœì°¨ ì‹¤í–‰ íë¦„
            # input_validation â†’ culture â†’ compensation â†’ growth â†’ career_analysis â†’ synthesis â†’ report_generation â†’ END
            workflow.add_edge("input_validation", "culture_analysis")
            workflow.add_edge("culture_analysis", "compensation_analysis")
            workflow.add_edge("compensation_analysis", "growth_analysis")
            workflow.add_edge("growth_analysis", "career_analysis")
        
        # ðŸ“Š ê³µí†µ íë¦„ (ì‹¤í–‰ ëª¨ë“œì™€ ë¬´ê´€)
        workflow.add_edge("career_analysis", "synthesis")
        workflow.add_edge("synthesis", "report_generation")
        workflow.add_edge("report_generation", END)
        
        # ðŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆ ë…¸ë“œ ì—°ê²° ì˜ˆì‹œ
        # ë¦¬ìŠ¤í¬ ë¶„ì„ì„ synthesis ì „ì— ì¶”ê°€í•˜ëŠ” ê²½ìš°:
        # workflow.add_edge("career_analysis", "risk_analysis")
        # workflow.add_edge("risk_analysis", "synthesis")
    
    # Node wrapper methods for LangGraph integration
    async def _input_validation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for input validation node."""
        node = InputValidationNode()
        return await node.execute(state)
    
    async def _culture_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for culture analysis node."""
        node = CultureAnalysisNode()
        return await node.execute(state)
    
    async def _compensation_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for compensation analysis node."""
        node = CompensationAnalysisNode()
        return await node.execute(state)
    
    async def _growth_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for growth analysis node."""
        node = GrowthAnalysisNode()
        return await node.execute(state)
    
    async def _career_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for career analysis node."""
        node = CareerAnalysisNode()
        return await node.execute(state)
    
    async def _parallel_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for parallel analysis node."""
        node = ParallelAnalysisNode()
        return await node.execute(state)
    
    async def _synthesis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for synthesis node."""
        node = SynthesisNode()
        return await node.execute(state)
    
    async def _report_generation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for report generation node."""
        node = ReportGenerationNode()
        return await node.execute(state)
    
    async def analyze_company(
        self,
        request: AnalysisRequest,
        user_profile: Optional[UserProfile] = None,
        thread_id: Optional[str] = None
    ) -> WorkflowState:
        """
        Execute comprehensive company analysis workflow.
        
        Args:
            request: Analysis request with company and position details
            user_profile: Optional user profile for personalized analysis
            thread_id: Optional thread ID for workflow checkpointing
            
        Returns:
            Final workflow state with comprehensive analysis results
        """
        
        # Generate unique workflow ID and thread ID
        workflow_id = str(uuid.uuid4())
        if not thread_id:
            thread_id = f"analysis_{workflow_id}"
        
        # Initialize workflow state
        initial_state = WorkflowState(
            request=request,
            user_profile=user_profile,
            workflow_id=workflow_id,
            debug_mode=self.config.enable_debug_logging
        )
        
        # Configure checkpointing
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            # Execute workflow
            result = await self.workflow_graph.ainvoke(
                initial_state.dict(),
                config=config
            )
            
            # Convert result back to WorkflowState
            final_state = WorkflowState(**result)
            
            return final_state
            
        except Exception as e:
            # Handle workflow execution errors
            initial_state.add_error(f"Workflow execution failed: {str(e)}")
            return initial_state
    
    async def get_workflow_state(self, thread_id: str) -> Optional[WorkflowState]:
        """Get current workflow state by thread ID."""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            checkpoints = self.checkpointer.list(config)
            
            if checkpoints:
                latest_checkpoint = max(checkpoints, key=lambda x: x.ts)
                return WorkflowState(**latest_checkpoint.checkpoint["channel_values"])
            
            return None
            
        except Exception:
            return None
    
    def get_workflow_history(self, thread_id: str) -> List[Dict]:
        """Get workflow execution history."""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            return list(self.checkpointer.list(config))
        except Exception:
            return []


class AnalysisWorkflow:
    """
    Simplified workflow interface for direct analysis execution.
    
    This class provides a simpler interface for executing analysis workflows
    without dealing with LangGraph complexities directly.
    """
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.workflow = BlindInsightWorkflow(config)
    
    async def analyze(
        self,
        company: str,
        position: Optional[str] = None,
        user_profile: Optional[UserProfile] = None,
        analysis_type: str = "comprehensive"
    ) -> Dict:
        """
        Execute company analysis with simplified parameters.
        
        Args:
            company: Company name to analyze
            position: Optional position/role
            user_profile: Optional user profile for personalization
            analysis_type: Type of analysis to perform
            
        Returns:
            Dictionary with analysis results
        """
        
        # Create analysis request
        request = AnalysisRequest(
            company=company,
            position=position,
            analysis_type=analysis_type
        )
        
        # Execute workflow
        result_state = await self.workflow.analyze_company(
            request=request,
            user_profile=user_profile
        )
        
        # Return formatted results
        return {
            "success": not result_state.has_errors(),
            "workflow_id": result_state.workflow_id,
            "progress": result_state.progress,
            "results": result_state.get_analysis_results(),
            "errors": list(result_state.errors),
            "warnings": list(result_state.warnings),
            "performance": result_state.get_performance_summary(),
            "completed_at": result_state.updated_at.isoformat()
        }


def create_analysis_workflow(
    enable_parallel: bool = True,
    enable_caching: bool = True,
    debug_mode: bool = False
) -> BlindInsightWorkflow:
    """
    Factory function to create a configured BlindInsight workflow.
    
    Args:
        enable_parallel: Enable parallel execution of analysis agents
        enable_caching: Enable result caching
        debug_mode: Enable debug logging
        
    Returns:
        Configured BlindInsightWorkflow instance
    """
    
    config = WorkflowConfig(
        enable_parallel_execution=enable_parallel,
        enable_caching=enable_caching,
        enable_debug_logging=debug_mode
    )
    
    return BlindInsightWorkflow(config)


def create_simple_workflow() -> AnalysisWorkflow:
    """Create a simple analysis workflow with default configuration."""
    return AnalysisWorkflow()


# Workflow execution utilities
async def execute_quick_analysis(
    company: str,
    position: Optional[str] = None
) -> Dict:
    """
    Execute a quick company analysis with minimal configuration.
    
    Args:
        company: Company name to analyze
        position: Optional position/role
        
    Returns:
        Analysis results dictionary
    """
    
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        analysis_type="comprehensive"
    )


async def execute_personalized_analysis(
    company: str,
    position: str,
    user_profile: UserProfile
) -> Dict:
    """
    Execute personalized company analysis with user profile.
    
    Args:
        company: Company name to analyze
        position: Position/role
        user_profile: User profile for personalization
        
    Returns:
        Personalized analysis results dictionary
    """
    
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        user_profile=user_profile,
        analysis_type="comprehensive"
    )