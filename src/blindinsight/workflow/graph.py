"""
LangGraph ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„± ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - ì´ˆë³´ì ê°€ì´ë“œ

ğŸ¯ StateGraphë€?
StateGraphëŠ” LangGraphì˜ í•µì‹¬ìœ¼ë¡œ, ë…¸ë“œë“¤ ê°„ì˜ ì—°ê²°ê³¼ ì‹¤í–‰ ìˆœì„œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ê° ë…¸ë“œëŠ” í•¨ìˆ˜ì´ê³ , ì—£ì§€(Edge)ëŠ” ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²°ì„ ì…ë‹ˆë‹¤.

ğŸ—ï¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ìš”ì†Œ:
1. StateGraph(WorkflowState): ìƒíƒœ í´ë˜ìŠ¤ë¥¼ ì§€ì •í•˜ì—¬ ê·¸ë˜í”„ ìƒì„±
2. add_node(): ë…¸ë“œ(í•¨ìˆ˜) ì¶”ê°€
3. add_edge(): ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²° ì •ì˜
4. set_entry_point(): ì‹œì‘ ë…¸ë“œ ì§€ì •
5. compile(): ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ì»´íŒŒì¼

ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
1. ìƒˆ ë…¸ë“œ ì¶”ê°€:
   - workflow.add_node("node_name", node_function)
   - ì ì ˆí•œ ìœ„ì¹˜ì— ì—£ì§€ ì—°ê²°

2. ì‹¤í–‰ íë¦„ ë³€ê²½:
   - ì—£ì§€ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ë…¸ë“œ ì‹¤í–‰ ìˆœì„œ ë³€ê²½
   - ì¡°ê±´ë¶€ ì—£ì§€ë¡œ ë¶„ê¸° ì²˜ë¦¬ ê°€ëŠ¥

3. ë³‘ë ¬/ìˆœì°¨ ì‹¤í–‰ ì „í™˜:
   - config.enable_parallel_executionìœ¼ë¡œ ì œì–´
   - _define_workflow_edges()ì—ì„œ íë¦„ ì •ì˜

4. ì²´í¬í¬ì¸íŒ…:
   - MemorySaverë¡œ ì¤‘ê°„ ìƒíƒœ ì €ì¥
   - ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥
"""

import uuid
from datetime import datetime
from typing import Dict, List, Optional

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from ..models.analysis import AnalysisRequest
from ..models.user import UserProfile
from .state import WorkflowState, WorkflowConfig
from .nodes import (
    InputValidationNode, CultureAnalysisNode, CompensationAnalysisNode,
    GrowthAnalysisNode, CareerAnalysisNode, ParallelAnalysisNode,
    SynthesisNode, ReportGenerationNode
)


class BlindInsightWorkflow:
    """
    ğŸ¯ BlindInsight AI ë¶„ì„ ì‹œìŠ¤í…œì˜ ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    
    LangGraph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ì—¬ ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ê³ 
    ì¢…í•©ì ì¸ ê¸°ì—… ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ğŸ—ï¸ ì›Œí¬í”Œë¡œìš° ì•„í‚¤í…ì²˜:
    
    ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ culture_analysis â†’ compensation_analysis â†’ growth_analysis â†’ career_analysis â†’ synthesis â†’ report_generation
    
    ë³‘ë ¬ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ parallel_analysis (culture + compensation + growth ë™ì‹œ ì‹¤í–‰) â†’ career_analysis â†’ synthesis â†’ report_generation
    
    ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
    1. ìƒˆë¡œìš´ ë¶„ì„ íƒ€ì… ì¶”ê°€:
       - ìƒˆ ë…¸ë“œ ë˜í¼ ë©”ì„œë“œ ì¶”ê°€ (_your_analysis_wrapper)
       - _build_workflow()ì—ì„œ ë…¸ë“œ ì¶”ê°€
       - _define_workflow_edges()ì—ì„œ ì—°ê²° ì •ì˜
    
    2. ì‹¤í–‰ ëª¨ë“œ ë³€ê²½:
       - WorkflowConfigì˜ enable_parallel_executionìœ¼ë¡œ ì œì–´
       - ë³‘ë ¬ ëª¨ë“œ: ë…ë¦½ì ì¸ ë¶„ì„ë“¤ì„ ë™ì‹œ ì‹¤í–‰í•˜ì—¬ ì†ë„ í–¥ìƒ
       - ìˆœì°¨ ëª¨ë“œ: ë‹¨ê³„ë³„ ìˆœì„œ ì‹¤í–‰ìœ¼ë¡œ ë””ë²„ê¹… ìš©ì´
    
    3. ì²´í¬í¬ì¸íŒ… í™œìš©:
       - thread_idë¡œ ì„¸ì…˜ ê´€ë¦¬
       - ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥
       - ì§„í–‰ ìƒí™© ì¶”ì  ë° ë³µêµ¬
    """
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.config = config or WorkflowConfig()
        self.workflow_graph = None
        self.checkpointer = MemorySaver()
        self._build_workflow()
    
    def _build_workflow(self) -> None:
        """
        ğŸ—ï¸ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± - í•µì‹¬ ë©”ì„œë“œ
        
        ğŸ”„ êµ¬ì„± ìˆœì„œ:
        1. StateGraph ìƒì„± (ìƒíƒœ í´ë˜ìŠ¤ ì§€ì •)
        2. ë…¸ë“œë“¤ ì¶”ê°€ (ê°ê° í•¨ìˆ˜ë¡œ ë“±ë¡)
        3. ì—£ì§€ë“¤ ì •ì˜ (ë…¸ë“œ ê°„ ì—°ê²°)
        4. ì§„ì…ì  ì„¤ì • (ì‹œì‘ ë…¸ë“œ)
        5. ì»´íŒŒì¼ (ì‹¤í–‰ ê°€ëŠ¥í•œ ê·¸ë˜í”„ë¡œ ë³€í™˜)
        
        ğŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§• í¬ì¸íŠ¸:
        - ìƒˆ ë…¸ë“œ ì¶”ê°€: workflow.add_node("name", wrapper_function)
        - ì‹¤í–‰ ëª¨ë“œ: config.enable_parallel_executionìœ¼ë¡œ ì œì–´
        """
        
        # 1ï¸âƒ£ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± (ìƒíƒœ í´ë˜ìŠ¤ ì§€ì •)
        workflow = StateGraph(WorkflowState)
        
        # 2ï¸âƒ£ ë…¸ë“œë“¤ ì¶”ê°€ - ê° ë…¸ë“œëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë“±ë¡
        workflow.add_node("input_validation", self._input_validation_wrapper)
        
        # ğŸ’¡ ì‹¤í–‰ ëª¨ë“œì— ë”°ë¥¸ ë…¸ë“œ êµ¬ì„±
        if self.config.enable_parallel_execution:
            # ğŸš€ ë³‘ë ¬ ì‹¤í–‰: culture, compensation, growthë¥¼ í•œ ë²ˆì—
            workflow.add_node("parallel_analysis", self._parallel_analysis_wrapper)
        else:
            # ğŸ”„ ìˆœì°¨ ì‹¤í–‰: ê° ë¶„ì„ì„ ë‹¨ê³„ì ìœ¼ë¡œ
            workflow.add_node("culture_analysis", self._culture_analysis_wrapper)
            workflow.add_node("compensation_analysis", self._compensation_analysis_wrapper)
            workflow.add_node("growth_analysis", self._growth_analysis_wrapper)
        
        # ğŸ¯ ê³µí†µ ë…¸ë“œë“¤ (ì‹¤í–‰ ëª¨ë“œì™€ ë¬´ê´€)
        workflow.add_node("career_analysis", self._career_analysis_wrapper)
        workflow.add_node("synthesis", self._synthesis_wrapper)
        workflow.add_node("report_generation", self._report_generation_wrapper)
        
        # ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆ ë…¸ë“œ ì¶”ê°€ ì˜ˆì‹œ
        # workflow.add_node("risk_analysis", self._risk_analysis_wrapper)
        
        # 3ï¸âƒ£ ì›Œí¬í”Œë¡œìš° ì—°ê²° ì •ì˜ (ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
        self._define_workflow_edges(workflow)
        
        # 4ï¸âƒ£ ì§„ì…ì  ì„¤ì • (ì²« ë²ˆì§¸ë¡œ ì‹¤í–‰ë  ë…¸ë“œ)
        workflow.set_entry_point("input_validation")
        
        # 5ï¸âƒ£ ì»´íŒŒì¼ - ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ë³€í™˜ (ì²´í¬í¬ì¸íŒ… í¬í•¨)
        self.workflow_graph = workflow.compile(checkpointer=self.checkpointer)
    
    def _define_workflow_edges(self, workflow: StateGraph) -> None:
        """
        ğŸ”— ì›Œí¬í”Œë¡œìš° ì—£ì§€(ì—°ê²°) ì •ì˜ - ë…¸ë“œ ê°„ ì‹¤í–‰ ìˆœì„œ ê²°ì •
        
        ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
        1. ìƒˆ ë…¸ë“œ ì‚½ì…: ê¸°ì¡´ ì—£ì§€ ì œê±° í›„ ìƒˆ ì—£ì§€ ì¶”ê°€
           ì˜ˆ: A -> C ì‚¬ì´ì— B ì‚½ì…
           ê¸°ì¡´: workflow.add_edge(A, C)
           ë³€ê²½: workflow.add_edge(A, B) + workflow.add_edge(B, C)
        
        2. ì¡°ê±´ë¶€ ë¶„ê¸°: ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ì—°ê²°
        3. ë³‘ë ¬ vs ìˆœì°¨: ì„¤ì •ì— ë”°ë¼ ë‹¤ë¥¸ íë¦„ êµ¬ì„±
        """
        
        if self.config.enable_parallel_execution:
            # ğŸš€ ë³‘ë ¬ ì‹¤í–‰ íë¦„
            # input_validation â†’ parallel_analysis â†’ career_analysis â†’ synthesis â†’ report_generation â†’ END
            workflow.add_edge("input_validation", "parallel_analysis")
            workflow.add_edge("parallel_analysis", "career_analysis")
        else:
            # ğŸ”„ ìˆœì°¨ ì‹¤í–‰ íë¦„
            # input_validation â†’ culture â†’ compensation â†’ growth â†’ career_analysis â†’ synthesis â†’ report_generation â†’ END
            workflow.add_edge("input_validation", "culture_analysis")
            workflow.add_edge("culture_analysis", "compensation_analysis")
            workflow.add_edge("compensation_analysis", "growth_analysis")
            workflow.add_edge("growth_analysis", "career_analysis")
        
        # ğŸ“Š ê³µí†µ íë¦„ (ì‹¤í–‰ ëª¨ë“œì™€ ë¬´ê´€)
        workflow.add_edge("career_analysis", "synthesis")
        workflow.add_edge("synthesis", "report_generation")
        workflow.add_edge("report_generation", END)
        
        # ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆ ë…¸ë“œ ì—°ê²° ì˜ˆì‹œ
        # ë¦¬ìŠ¤í¬ ë¶„ì„ì„ synthesis ì „ì— ì¶”ê°€í•˜ëŠ” ê²½ìš°:
        # workflow.add_edge("career_analysis", "risk_analysis")
        # workflow.add_edge("risk_analysis", "synthesis")
    
    # Node wrapper methods for LangGraph integration
    async def _input_validation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for input validation node."""
        node = InputValidationNode()
        return await node.execute(state)
    
    async def _culture_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for culture analysis node."""
        node = CultureAnalysisNode()
        return await node.execute(state)
    
    async def _compensation_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for compensation analysis node."""
        node = CompensationAnalysisNode()
        return await node.execute(state)
    
    async def _growth_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for growth analysis node."""
        node = GrowthAnalysisNode()
        return await node.execute(state)
    
    async def _career_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for career analysis node."""
        node = CareerAnalysisNode()
        return await node.execute(state)
    
    async def _parallel_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for parallel analysis node."""
        node = ParallelAnalysisNode()
        return await node.execute(state)
    
    async def _synthesis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for synthesis node."""
        node = SynthesisNode()
        return await node.execute(state)
    
    async def _report_generation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """Wrapper for report generation node."""
        node = ReportGenerationNode()
        return await node.execute(state)
    
    async def analyze_company(
        self,
        request: AnalysisRequest,
        user_profile: Optional[UserProfile] = None,
        thread_id: Optional[str] = None
    ) -> WorkflowState:
        """
        ê¸°ì—… ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰í•˜ê¸°
        - ì‚¬ìš©ì ìš”ì²­ì„ ë°›ì•„ì„œ ì „ì²´ ë¶„ì„ ê³¼ì •ì„ ì§„í–‰
        - ìµœì¢… ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì€ ìƒíƒœ ê°ì²´ ë°˜í™˜
        """
        
        # Generate unique workflow ID and thread ID
        workflow_id = str(uuid.uuid4())
        if not thread_id:
            thread_id = f"analysis_{workflow_id}"
        
        # Initialize workflow state
        initial_state = WorkflowState(
            request=request,
            user_profile=user_profile,
            workflow_id=workflow_id,
            debug_mode=self.config.enable_debug_logging
        )
        
        # Configure checkpointing
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            # Execute workflow
            result = await self.workflow_graph.ainvoke(
                initial_state.dict(),
                config=config
            )
            
            # Convert result back to WorkflowState
            final_state = WorkflowState(**result)
            
            return final_state
            
        except Exception as e:
            # Handle workflow execution errors
            initial_state.add_error(f"Workflow execution failed: {str(e)}")
            return initial_state
    
    async def get_workflow_state(self, thread_id: str) -> Optional[WorkflowState]:
        """Get current workflow state by thread ID."""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            checkpoints = self.checkpointer.list(config)
            
            if checkpoints:
                latest_checkpoint = max(checkpoints, key=lambda x: x.ts)
                return WorkflowState(**latest_checkpoint.checkpoint["channel_values"])
            
            return None
            
        except Exception:
            return None
    
    def get_workflow_history(self, thread_id: str) -> List[Dict]:
        """Get workflow execution history."""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            return list(self.checkpointer.list(config))
        except Exception:
            return []


class AnalysisWorkflow:
    """
    ë¶„ì„ ì›Œí¬í”Œë¡œìš° ê°„í¸ ì¸í„°í˜ì´ìŠ¤
    - BlindInsightWorkflowë¥¼ ë” ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë˜í•‘
    - ë³µì¡í•œ LangGraph ì„¤ì •ì„ ìˆ¨ê¸°ê³  ë‹¨ìˆœí•œ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
    """
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.workflow = BlindInsightWorkflow(config)
    
    async def analyze(
        self,
        company: str,
        position: Optional[str] = None,
        user_profile: Optional[UserProfile] = None,
        analysis_type: str = "comprehensive"
    ) -> Dict:
        """
        ê¸°ì—… ë¶„ì„ ì‹¤í–‰í•˜ê¸° (ê°„í¸ ë²„ì „)
        - ë‹¨ìˆœí•œ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        - ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
        """
        
        # Create analysis request
        request = AnalysisRequest(
            company=company,
            position=position,
            analysis_type=analysis_type
        )
        
        # Execute workflow
        result_state = await self.workflow.analyze_company(
            request=request,
            user_profile=user_profile
        )
        
        # Return formatted results
        return {
            "success": not result_state.has_errors(),
            "workflow_id": result_state.workflow_id,
            "progress": result_state.progress,
            "results": result_state.get_analysis_results(),
            "errors": list(result_state.errors),
            "warnings": list(result_state.warnings),
            "performance": result_state.get_performance_summary(),
            "completed_at": result_state.updated_at.isoformat()
        }


def create_analysis_workflow(
    enable_parallel: bool = True,
    enable_caching: bool = True,
    debug_mode: bool = False
) -> BlindInsightWorkflow:
    """
   ì„¤ì •ì´ ì ìš©ëœ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ìƒì„±í•˜ê¸°
    - ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì˜µì…˜ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±
    """
    
    config = WorkflowConfig(
        enable_parallel_execution=enable_parallel,
        enable_caching=enable_caching,
        enable_debug_logging=debug_mode
    )
    
    return BlindInsightWorkflow(config)


def create_simple_workflow() -> AnalysisWorkflow:
    """ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê°„í¸ ì›Œí¬í”Œë¡œìš° ìƒì„±í•˜ê¸°"""
    return AnalysisWorkflow()


# Workflow execution utilities
async def execute_quick_analysis(
    company: str,
    position: Optional[str] = None
) -> Dict:
    """
   ë¹ ë¥¸ ê¸°ì—… ë¶„ì„ ì‹¤í–‰í•˜ê¸°
    - ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ì¦‰ì‹œ ë¶„ì„ ì‹œì‘
    - íšŒì‚¬ëª…ë§Œ ì…ë ¥í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥
    """
    
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        analysis_type="comprehensive"
    )


async def execute_personalized_analysis(
    company: str,
    position: str,
    user_profile: UserProfile
) -> Dict:
    """
    ê°œì¸í™”ëœ ê¸°ì—… ë¶„ì„ ì‹¤í–‰í•˜ê¸°
    - ì‚¬ìš©ì í”„ë¡œí•„ì„ í™œìš©í•œ ë§ì¶¤í˜• ë¶„ì„
    - ê°œì¸ì˜ íŠ¹ì„±ì— ë§ëŠ” ë¶„ì„ ê²°ê³¼ ì œê³µ
    """
    
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        user_profile=user_profile,
        analysis_type="comprehensive"
    )