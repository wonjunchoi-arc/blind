"""
LangGraph ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„± ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - ì´ˆë³´ì ê°€ì´ë“œ

ğŸ¯ StateGraphë€?
StateGraphëŠ” LangGraphì˜ í•µì‹¬ìœ¼ë¡œ, ë…¸ë“œë“¤ ê°„ì˜ ì—°ê²°ê³¼ ì‹¤í–‰ ìˆœì„œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ê° ë…¸ë“œëŠ” í•¨ìˆ˜ì´ê³ , ì—£ì§€(Edge)ëŠ” ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²°ì„ ì…ë‹ˆë‹¤.

ğŸ—ï¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ìš”ì†Œ:
1. StateGraph(WorkflowState): ìƒíƒœ í´ë˜ìŠ¤ë¥¼ ì§€ì •í•˜ì—¬ ê·¸ë˜í”„ ìƒì„±
2. add_node(): ë…¸ë“œ(í•¨ìˆ˜) ì¶”ê°€
3. add_edge(): ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²° ì •ì˜
4. set_entry_point(): ì‹œì‘ ë…¸ë“œ ì§€ì •
5. compile(): ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ì»´íŒŒì¼

ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
1. ìƒˆ ë…¸ë“œ ì¶”ê°€:
   - workflow.add_node("node_name", node_function)
   - ì ì ˆí•œ ìœ„ì¹˜ì— ì—£ì§€ ì—°ê²°

2. ì‹¤í–‰ íë¦„ ë³€ê²½:
   - ì—£ì§€ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ë…¸ë“œ ì‹¤í–‰ ìˆœì„œ ë³€ê²½
   - ì¡°ê±´ë¶€ ì—£ì§€ë¡œ ë¶„ê¸° ì²˜ë¦¬ ê°€ëŠ¥

3. ë³‘ë ¬/ìˆœì°¨ ì‹¤í–‰ ì „í™˜:
   - config.enable_parallel_executionìœ¼ë¡œ ì œì–´
   - _define_workflow_edges()ì—ì„œ íë¦„ ì •ì˜

4. ì²´í¬í¬ì¸íŒ…:
   - MemorySaverë¡œ ì¤‘ê°„ ìƒíƒœ ì €ì¥
   - ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥
"""
#graph.py
"""
LangGraph ì›Œí¬í”Œë¡œìš° - ì—ì´ì „íŠ¸ êµ¬ì¡° ìµœì í™”

5ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ì— ë§ì¶˜ ì›Œí¬í”Œë¡œìš°:
- CompanyCultureAgent, WorkLifeBalanceAgent, ManagementAgent, SalaryBenefitsAgent, CareerGrowthAgent
- ìˆœì°¨ ì‹¤í–‰ê³¼ ë³‘ë ¬ ì‹¤í–‰ ëª¨ë“œ ì§€ì›
- ë¶ˆí•„ìš”í•œ ë³µì¡ì„± ì œê±° ë° ì„±ëŠ¥ ìµœì í™”
"""

import uuid
from datetime import datetime
from typing import Dict, List, Optional

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from ..models.analysis import AnalysisRequest
from ..models.user import UserProfile
from .state import WorkflowState, WorkflowConfig
from .nodes import (
    InputValidationNode,
    CompanyCultureNode,
    WorkLifeBalanceNode,
    ManagementNode,
    SalaryBenefitsNode,
    CareerGrowthNode,
    ParallelAnalysisNode,
    SynthesisNode,
    ReportGenerationNode
)


class BlindInsightWorkflow:
    """
    BlindInsight AI ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    
    5ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ì—¬ ì¢…í•©ì ì¸ ê¸°ì—… ë¶„ì„ ìˆ˜í–‰:
    
    ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ company_culture â†’ work_life_balance â†’ management â†’ salary_benefits â†’ career_growth â†’ synthesis â†’ report_generation
    
    ë³‘ë ¬ ì‹¤í–‰ ëª¨ë“œ:
    input_validation â†’ parallel_analysis (5ê°œ ì—ì´ì „íŠ¸ ë™ì‹œ ì‹¤í–‰) â†’ synthesis â†’ report_generation
    """
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.config = config or WorkflowConfig()
        self.workflow_graph = None
        self.checkpointer = MemorySaver()
        self._build_workflow()
    
    def _build_workflow(self) -> None:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(WorkflowState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("input_validation", self._input_validation_wrapper)
        
        if self.config.enable_parallel_execution:
            # ë³‘ë ¬ ì‹¤í–‰: 5ê°œ ì—ì´ì „íŠ¸ë¥¼ í•œ ë²ˆì—
            workflow.add_node("parallel_analysis", self._parallel_analysis_wrapper)
        else:
            # ìˆœì°¨ ì‹¤í–‰: ê° ì—ì´ì „íŠ¸ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ
            workflow.add_node("company_culture_analysis", self._company_culture_wrapper)
            workflow.add_node("work_life_balance_analysis", self._work_life_balance_wrapper)
            workflow.add_node("management_analysis", self._management_wrapper)
            workflow.add_node("salary_benefits_analysis", self._salary_benefits_wrapper)
            workflow.add_node("career_growth_analysis", self._career_growth_wrapper)
        
        # ê³µí†µ ë…¸ë“œë“¤
        workflow.add_node("synthesis", self._synthesis_wrapper)
        workflow.add_node("report_generation", self._report_generation_wrapper)
        
        # ì›Œí¬í”Œë¡œìš° ì—°ê²° ì •ì˜
        self._define_workflow_edges(workflow)
        
        # ì§„ì…ì  ì„¤ì •
        workflow.set_entry_point("input_validation")
        
        # ì»´íŒŒì¼
        self.workflow_graph = workflow.compile(checkpointer=self.checkpointer)
    
    def _define_workflow_edges(self, workflow: StateGraph) -> None:
        """ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì •ì˜"""
        if self.config.enable_parallel_execution:
            # ë³‘ë ¬ ì‹¤í–‰ íë¦„
            workflow.add_edge("input_validation", "parallel_analysis")
            workflow.add_edge("parallel_analysis", "synthesis")
        else:
            # ìˆœì°¨ ì‹¤í–‰ íë¦„
            workflow.add_edge("input_validation", "company_culture_analysis")
            workflow.add_edge("company_culture_analysis", "work_life_balance_analysis")
            workflow.add_edge("work_life_balance_analysis", "management_analysis")
            workflow.add_edge("management_analysis", "salary_benefits_analysis")
            workflow.add_edge("salary_benefits_analysis", "career_growth_analysis")
            workflow.add_edge("career_growth_analysis", "synthesis")
        
        # ê³µí†µ íë¦„
        workflow.add_edge("synthesis", "report_generation")
        workflow.add_edge("report_generation", END)
    
    # ë…¸ë“œ ë˜í¼ ë©”ì„œë“œë“¤
    async def _input_validation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ì…ë ¥ ê²€ì¦ ë…¸ë“œ ë˜í¼"""
        node = InputValidationNode()
        return await node.execute(state)
    
    async def _company_culture_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ê¸°ì—…ë¬¸í™” ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = CompanyCultureNode()
        return await node.execute(state)
    
    async def _work_life_balance_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ì›Œë¼ë°¸ ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = WorkLifeBalanceNode()
        return await node.execute(state)
    
    async def _management_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ê²½ì˜ì§„ ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = ManagementNode()
        return await node.execute(state)
    
    async def _salary_benefits_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ì—°ë´‰/ë³µì§€ ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = SalaryBenefitsNode()
        return await node.execute(state)
    
    async def _career_growth_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ì»¤ë¦¬ì–´ ì„±ì¥ ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = CareerGrowthNode()
        return await node.execute(state)
    
    async def _parallel_analysis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ë³‘ë ¬ ë¶„ì„ ë…¸ë“œ ë˜í¼"""
        node = ParallelAnalysisNode()
        return await node.execute(state)
    
    async def _synthesis_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ê²°ê³¼ ì¢…í•© ë…¸ë“œ ë˜í¼"""
        node = SynthesisNode()
        return await node.execute(state)
    
    async def _report_generation_wrapper(self, state: WorkflowState) -> WorkflowState:
        """ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ ë˜í¼"""
        node = ReportGenerationNode()
        return await node.execute(state)
    
    async def analyze_company(
        self,
        request: AnalysisRequest,
        user_profile: Optional[UserProfile] = None,
        thread_id: Optional[str] = None
    ) -> WorkflowState:
        """ê¸°ì—… ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        # ì›Œí¬í”Œë¡œìš° ID ë° ìŠ¤ë ˆë“œ ID ìƒì„±
        workflow_id = str(uuid.uuid4())
        if not thread_id:
            thread_id = f"analysis_{workflow_id}"
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = WorkflowState(
            request=request,
            user_profile=user_profile,
            workflow_id=workflow_id,
            debug_mode=self.config.enable_debug_logging
        )
        
        # ì²´í¬í¬ì¸íŒ… ì„¤ì •
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow_graph.ainvoke(
                initial_state.dict(),
                config=config
            )
            
            # ê²°ê³¼ë¥¼ WorkflowStateë¡œ ë³€í™˜
            final_state = WorkflowState(**result)
            
            return final_state
            
        except Exception as e:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜¤ë¥˜ ì²˜ë¦¬
            initial_state.add_error(f"Workflow execution failed: {str(e)}")
            return initial_state
    
    async def get_workflow_state(self, thread_id: str) -> Optional[WorkflowState]:
        """ìŠ¤ë ˆë“œ IDë¡œ í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ"""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            checkpoints = self.checkpointer.list(config)
            
            if checkpoints:
                latest_checkpoint = max(checkpoints, key=lambda x: x.ts)
                return WorkflowState(**latest_checkpoint.checkpoint["channel_values"])
            
            return None
            
        except Exception:
            return None
    
    def get_workflow_history(self, thread_id: str) -> List[Dict]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        try:
            config = {"configurable": {"thread_id": thread_id}}
            return list(self.checkpointer.list(config))
        except Exception:
            return []


class AnalysisWorkflow:
    """ê°„í¸ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, config: Optional[WorkflowConfig] = None):
        self.workflow = BlindInsightWorkflow(config)
    
    async def analyze(
        self,
        company: str,
        position: Optional[str] = None,
        user_profile: Optional[UserProfile] = None,
        analysis_type: str = "comprehensive"
    ) -> Dict:
        """ê¸°ì—… ë¶„ì„ ì‹¤í–‰ (ê°„í¸ ë²„ì „)"""
        
        # ë¶„ì„ ìš”ì²­ ìƒì„±
        request = AnalysisRequest(
            company=company,
            position=position,
            analysis_type=analysis_type
        )
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result_state = await self.workflow.analyze_company(
            request=request,
            user_profile=user_profile
        )
        
        # í¬ë§·ëœ ê²°ê³¼ ë°˜í™˜
        return {
            "success": not result_state.has_errors(),
            "workflow_id": result_state.workflow_id,
            "progress": result_state.progress,
            "results": result_state.get_all_results(),
            "errors": list(result_state.errors),
            "warnings": list(result_state.warnings),
            "performance": result_state.get_performance_summary(),
            "completed_at": result_state.updated_at.isoformat()
        }


# ì›Œí¬í”Œë¡œìš° ìƒì„± ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def create_analysis_workflow(
    enable_parallel: bool = True,
    enable_caching: bool = True,
    debug_mode: bool = False
) -> BlindInsightWorkflow:
    """ì„¤ì •ì´ ì ìš©ëœ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    config = WorkflowConfig(
        enable_parallel_execution=enable_parallel,
        enable_caching=enable_caching,
        enable_debug_logging=debug_mode
    )
    
    return BlindInsightWorkflow(config)


def create_simple_workflow() -> AnalysisWorkflow:
    """ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê°„í¸ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    return AnalysisWorkflow()


# ë¹ ë¥¸ ì‹¤í–‰ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
async def execute_quick_analysis(
    company: str,
    position: Optional[str] = None
) -> Dict:
    """ë¹ ë¥¸ ê¸°ì—… ë¶„ì„ ì‹¤í–‰"""
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        analysis_type="comprehensive"
    )


async def execute_personalized_analysis(
    company: str,
    position: str,
    user_profile: UserProfile
) -> Dict:
    """ê°œì¸í™”ëœ ê¸°ì—… ë¶„ì„ ì‹¤í–‰"""
    workflow = create_simple_workflow()
    return await workflow.analyze(
        company=company,
        position=position,
        user_profile=user_profile,
        analysis_type="comprehensive"
    )


async def execute_parallel_analysis(
    company: str,
    position: Optional[str] = None,
    debug_mode: bool = False
) -> Dict:
    """ë³‘ë ¬ ì²˜ë¦¬ ê¸°ì—… ë¶„ì„ ì‹¤í–‰"""
    config = WorkflowConfig(
        enable_parallel_execution=True,
        enable_debug_logging=debug_mode
    )
    workflow = AnalysisWorkflow(config)
    
    return await workflow.analyze(
        company=company,
        position=position,
        analysis_type="comprehensive"
    )


async def execute_sequential_analysis(
    company: str,
    position: Optional[str] = None,
    debug_mode: bool = False
) -> Dict:
    """ìˆœì°¨ ì²˜ë¦¬ ê¸°ì—… ë¶„ì„ ì‹¤í–‰"""
    config = WorkflowConfig(
        enable_parallel_execution=False,
        enable_debug_logging=debug_mode
    )
    workflow = AnalysisWorkflow(config)
    
    return await workflow.analyze(
        company=company,
        position=position,
        analysis_type="comprehensive"
    )