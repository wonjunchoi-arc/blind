"""
LangGraph ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬ - ì´ˆë³´ìž ê°€ì´ë“œ

ðŸ”¥ LangGraphì˜ í•µì‹¬ ê°œë…:
LangGraphëŠ” ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ëŠ” í”„ë ˆìž„ì›Œí¬ìž…ë‹ˆë‹¤.
ê° ë…¸ë“œëŠ” WorkflowStateë¥¼ ìž…ë ¥ë°›ì•„ ìˆ˜ì •ëœ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

ðŸ“š ì£¼ìš” ê°œë…ë“¤:
1. StateGraph: ì „ì²´ ì›Œí¬í”Œë¡œìš°ì˜ ê·¸ëž˜í”„ êµ¬ì¡°ë¥¼ ì •ì˜
2. WorkflowState: ëª¨ë“  ë…¸ë“œ ê°„ì— ê³µìœ ë˜ëŠ” ìƒíƒœ ê°ì²´
3. Node: ìƒíƒœë¥¼ ì²˜ë¦¬í•˜ëŠ” ê°œë³„ í•¨ìˆ˜/í´ëž˜ìŠ¤
4. Edge: ë…¸ë“œë“¤ ê°„ì˜ ì—°ê²°ê³¼ ì‹¤í–‰ ìˆœì„œ ì •ì˜

ðŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§• í¬ì¸íŠ¸:
- ìƒˆë¡œìš´ ë¶„ì„ íƒ€ìž… ì¶”ê°€í•˜ë ¤ë©´: ìƒˆ Report í•„ë“œì™€ í•´ë‹¹ ë…¸ë“œ ì¶”ê°€
- ì§„í–‰ë¥  ê³„ì‚° ë°©ì‹ ë³€ê²½í•˜ë ¤ë©´: update_progress ë©”ì„œë“œ ìˆ˜ì •
- ì—ëŸ¬ ì²˜ë¦¬ ë°©ì‹ ë³€ê²½í•˜ë ¤ë©´: add_error, add_warning ë©”ì„œë“œ ìˆ˜ì •
"""

import operator
from datetime import datetime
from typing import Annotated, Any, Dict, List, Optional, Sequence
from pydantic import Field

from ..models.base import BaseModel
from ..models.analysis import (
    AnalysisRequest, CultureReport, CompensationReport, 
    GrowthReport, CareerReport, ComprehensiveReport
)
from ..models.user import UserProfile


class WorkflowState(BaseModel):
    """
    ðŸŽ¯ LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ì¤‘ì•™ ìƒíƒœ í´ëž˜ìŠ¤
    
    ëª¨ë“  ë…¸ë“œê°€ ê³µìœ í•˜ëŠ” ìƒíƒœ ê°ì²´ìž…ë‹ˆë‹¤. ê° ë…¸ë“œëŠ” ì´ ê°ì²´ë¥¼ ë°›ì•„ì„œ ìˆ˜ì •í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ðŸ”„ LangGraph ìƒíƒœ ì „ì´ íŒ¨í„´:
    Node1(state) -> modified_state -> Node2(modified_state) -> ...
    
    ðŸ“ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ:
    1. ìƒˆ í•„ë“œ ì¶”ê°€í•˜ê¸°:
       new_field: Optional[YourType] = Field(None, description="ì„¤ëª…")
    
    2. ë¦¬ìŠ¤íŠ¸ í•„ë“œ ì¶”ê°€í•˜ê¸° (ì—¬ëŸ¬ ë…¸ë“œì—ì„œ ì•ˆì „í•˜ê²Œ ì¶”ê°€):
       new_list: Annotated[Sequence[YourType], operator.add] = Field(default_factory=list)
    
    3. ë”•ì…”ë„ˆë¦¬ í•„ë“œ ì¶”ê°€í•˜ê¸°:
       new_dict: Dict[str, Any] = Field(default_factory=dict)
    
    âš ï¸ ì¤‘ìš”: Annotated[Sequence, operator.add]ëŠ” ì—¬ëŸ¬ ë…¸ë“œì—ì„œ ë™ì‹œì— ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•  ë•Œ ì‚¬ìš©
    """
    
    # ðŸ“¥ ìž…ë ¥ íŒŒë¼ë¯¸í„° - ì›Œí¬í”Œë¡œìš° ì‹œìž‘ ì‹œ ì„¤ì •ë˜ëŠ” í•„ìˆ˜ ì •ë³´
    request: AnalysisRequest = Field(..., description="ì›ë³¸ ë¶„ì„ ìš”ì²­ ì •ë³´")
    user_profile: Optional[UserProfile] = Field(None, description="ê°œì¸í™”ë¥¼ ìœ„í•œ ì‚¬ìš©ìž í”„ë¡œí•„")
    
    # ðŸ“Š ë¶„ì„ ê²°ê³¼ - ê°ê°ì˜ ì „ë¬¸ ì—ì´ì „íŠ¸ì— ì˜í•´ ì±„ì›Œì§
    # ðŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆë¡œìš´ ë¶„ì„ íƒ€ìž…ì„ ì¶”ê°€í•˜ë ¤ë©´ ì—¬ê¸°ì— ìƒˆ Report í•„ë“œ ì¶”ê°€
    # ì˜ˆì‹œ: risk_report: Optional[RiskReport] = Field(None, description="ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼")
    culture_report: Optional[CultureReport] = Field(None, description="ê¸°ì—… ë¬¸í™” ë¶„ì„ ê²°ê³¼")
    compensation_report: Optional[CompensationReport] = Field(None, description="ë³´ìƒ ì²´ê³„ ë¶„ì„ ê²°ê³¼") 
    growth_report: Optional[GrowthReport] = Field(None, description="ì„±ìž¥ì„± ë¶„ì„ ê²°ê³¼")
    career_report: Optional[CareerReport] = Field(None, description="ì»¤ë¦¬ì–´ ê²½ë¡œ ë¶„ì„ ê²°ê³¼")
    final_report: Optional[ComprehensiveReport] = Field(None, description="ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸")
    
    # ðŸŽ›ï¸ ì›Œí¬í”Œë¡œìš° ì œì–´ - LangGraph ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬
    # ðŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ì§„í–‰ë¥  ê³„ì‚°ì„ ë³€ê²½í•˜ë ¤ë©´ update_progress() ë©”ì„œë“œ ìˆ˜ì •
    current_stage: str = Field("initialized", description="í˜„ìž¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œ ì´ë¦„")
    completed_stages: List[str] = Field(default_factory=list, description="ì™„ë£Œëœ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë“¤")
    progress: float = Field(0.0, ge=0.0, le=1.0, description="ì „ì²´ ì§„í–‰ë¥  (0.0-1.0)")
    
    # ðŸš¨ ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… - operator.add íŒ¨í„´ìœ¼ë¡œ ì—¬ëŸ¬ ë…¸ë“œì—ì„œ ì•ˆì „í•˜ê²Œ ì¶”ê°€
    # âš ï¸ ì¤‘ìš”: Annotated[Sequence[str], operator.add]ëŠ” ë³‘ë ¬ ë…¸ë“œì—ì„œë„ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    # ðŸ’¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•: ìƒˆë¡œìš´ ë¡œê·¸ íƒ€ìž…ì„ ì¶”ê°€í•˜ë ¤ë©´ ë¹„ìŠ·í•œ íŒ¨í„´ìœ¼ë¡œ í•„ë“œ ì¶”ê°€
    # ì˜ˆì‹œ: performance_logs: Annotated[Sequence[str], operator.add] = Field(default_factory=list)
    errors: Annotated[Sequence[str], operator.add] = Field(default_factory=list)
    warnings: Annotated[Sequence[str], operator.add] = Field(default_factory=list)
    debug_logs: Annotated[Sequence[str], operator.add] = Field(default_factory=list)
    
    # Data and cache management
    retrieved_documents: Dict[str, List[Dict[str, Any]]] = Field(
        default_factory=dict,
        description="RAG retrieved documents by category"
    )
    external_data: Dict[str, Any] = Field(
        default_factory=dict,
        description="External data from MCP services"
    )
    agent_outputs: Dict[str, Dict[str, Any]] = Field(
        default_factory=dict,
        description="Raw outputs from individual agents"
    )
    
    # Performance metrics
    stage_timings: Dict[str, float] = Field(
        default_factory=dict,
        description="Execution time for each stage in seconds"
    )
    api_call_counts: Dict[str, int] = Field(
        default_factory=dict,
        description="API call counts by service"
    )
    token_usage: Dict[str, int] = Field(
        default_factory=dict,
        description="Token usage by model/service"
    )
    
    # Workflow metadata
    workflow_id: str = Field(..., description="Unique workflow execution identifier")
    started_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    estimated_completion: Optional[datetime] = None
    
    # Configuration and flags
    skip_stages: List[str] = Field(default_factory=list, description="Stages to skip")
    force_refresh: bool = Field(False, description="Force refresh of cached data")
    debug_mode: bool = Field(False, description="Enable debug mode")
    
    class Config:
        """Pydantic configuration."""
        arbitrary_types_allowed = True
        validate_assignment = True
    
    def add_error(self, error: str, stage: Optional[str] = None) -> None:
        """Add an error to the workflow state."""
        error_msg = f"[{stage or self.current_stage}] {error}"
        # Note: Direct list modification works with Annotated[Sequence, operator.add]
        self.errors.append(error_msg)
        self.updated_at = datetime.now()
    
    def add_warning(self, warning: str, stage: Optional[str] = None) -> None:
        """Add a warning to the workflow state."""
        warning_msg = f"[{stage or self.current_stage}] {warning}"
        self.warnings.append(warning_msg)
        self.updated_at = datetime.now()
    
    def add_debug_log(self, message: str, stage: Optional[str] = None) -> None:
        """Add a debug log entry."""
        if self.debug_mode:
            log_msg = f"[{stage or self.current_stage}] {message}"
            self.debug_logs.append(log_msg)
    
    def update_stage(self, new_stage: str) -> None:
        """Update the current workflow stage."""
        if self.current_stage != "initialized":
            self.completed_stages.append(self.current_stage)
        self.current_stage = new_stage
        self.updated_at = datetime.now()
    
    def update_progress(self, progress: float) -> None:
        """Update the workflow progress."""
        self.progress = max(0.0, min(1.0, progress))
        self.updated_at = datetime.now()
    
    def record_stage_timing(self, stage: str, duration: float) -> None:
        """Record the execution time for a workflow stage."""
        self.stage_timings[stage] = duration
    
    def increment_api_calls(self, service: str, count: int = 1) -> None:
        """Increment API call count for a service."""
        self.api_call_counts[service] = self.api_call_counts.get(service, 0) + count
    
    def add_token_usage(self, model: str, tokens: int) -> None:
        """Add token usage for a model."""
        self.token_usage[model] = self.token_usage.get(model, 0) + tokens
    
    def store_retrieved_documents(self, category: str, documents: List[Dict[str, Any]]) -> None:
        """Store retrieved documents for a category."""
        self.retrieved_documents[category] = documents
        self.add_debug_log(f"Stored {len(documents)} documents for category: {category}")
    
    def store_external_data(self, source: str, data: Any) -> None:
        """Store external data from MCP services."""
        self.external_data[source] = data
        self.add_debug_log(f"Stored external data from source: {source}")
    
    def store_agent_output(self, agent_name: str, output: Dict[str, Any]) -> None:
        """Store raw output from an agent."""
        self.agent_outputs[agent_name] = output
        self.add_debug_log(f"Stored output from agent: {agent_name}")
    
    def has_errors(self) -> bool:
        """Check if the workflow has any errors."""
        return len(self.errors) > 0
    
    def get_completion_estimate(self) -> Optional[datetime]:
        """Get estimated completion time based on current progress."""
        if self.progress > 0 and self.started_at:
            elapsed = (datetime.now() - self.started_at).total_seconds()
            estimated_total = elapsed / self.progress
            return self.started_at + datetime.timedelta(seconds=estimated_total)
        return None
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get a summary of workflow performance metrics."""
        total_execution_time = sum(self.stage_timings.values())
        total_api_calls = sum(self.api_call_counts.values())
        total_tokens = sum(self.token_usage.values())
        
        return {
            "total_execution_time": total_execution_time,
            "total_api_calls": total_api_calls,
            "total_tokens": total_tokens,
            "stage_timings": self.stage_timings,
            "api_calls_by_service": self.api_call_counts,
            "tokens_by_model": self.token_usage,
            "error_count": len(self.errors),
            "warning_count": len(self.warnings)
        }
    
    def is_stage_completed(self, stage: str) -> bool:
        """Check if a specific stage has been completed."""
        return stage in self.completed_stages
    
    def should_skip_stage(self, stage: str) -> bool:
        """Check if a stage should be skipped."""
        return stage in self.skip_stages
    
    def get_analysis_results(self) -> Dict[str, Any]:
        """Get all available analysis results."""
        results = {}
        
        if self.culture_report:
            results["culture"] = self.culture_report.dict()
        if self.compensation_report:
            results["compensation"] = self.compensation_report.dict()
        if self.growth_report:
            results["growth"] = self.growth_report.dict()
        if self.career_report:
            results["career"] = self.career_report.dict()
        if self.final_report:
            results["comprehensive"] = self.final_report.dict()
        
        return results
    
    def validate_state(self) -> bool:
        """Validate the current workflow state."""
        # Check required fields
        if not self.request:
            self.add_error("Missing analysis request")
            return False
        
        if not self.workflow_id:
            self.add_error("Missing workflow ID")
            return False
        
        # Check progress consistency
        if self.progress < 0 or self.progress > 1:
            self.add_error(f"Invalid progress value: {self.progress}")
            return False
        
        # Check if final report exists when progress is complete
        if self.progress >= 1.0 and not self.final_report:
            self.add_warning("Progress indicates completion but no final report available")
        
        return not self.has_errors()


class WorkflowConfig(BaseModel):
    """Configuration for workflow execution."""
    
    # Execution settings
    max_execution_time: int = Field(120, description="Maximum execution time in seconds")
    enable_parallel_execution: bool = Field(True, description="Enable parallel agent execution")
    max_retries: int = Field(3, description="Maximum retries for failed stages")
    
    # Quality settings
    min_confidence_threshold: float = Field(0.7, description="Minimum confidence threshold")
    require_all_analyses: bool = Field(False, description="Require all analysis types to complete")
    
    # Performance settings
    enable_caching: bool = Field(True, description="Enable result caching")
    cache_ttl: int = Field(3600, description="Cache TTL in seconds")
    
    # Debug settings
    enable_debug_logging: bool = Field(False, description="Enable debug logging")
    save_intermediate_results: bool = Field(False, description="Save intermediate results")
    
    class Config:
        """Pydantic configuration."""
        schema_extra = {
            "example": {
                "max_execution_time": 120,
                "enable_parallel_execution": True,
                "min_confidence_threshold": 0.7,
                "enable_caching": True
            }
        }